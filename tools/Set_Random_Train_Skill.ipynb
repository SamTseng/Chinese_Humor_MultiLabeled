{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, csv, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"mlabel_corpora/JokeSkill.txt\"\n",
    "outp_path = \"mlabel_corpora/JokeSkill_train_random.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 11)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "#data_raw = df.loc[np.random.choice(data_raw.index, size=2000)]\n",
    "print(df.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 11)\n",
      "(1674, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ID=L1850 為分界，之前：吳玟萱，之後：黃亭筠，均為中文系同一屆\n",
    "train, test = train_test_split(df, train_size=1691, shuffle=False) \n",
    "# (tempararily) set global variables: train, test \n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now randomly assign labels to the training set and save it to file\n",
    "\n",
    "1. First, to know the original training label distribution.\n",
    "2. Set the labels based on this distribution, by apply an algorithm from stackoverflow.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.copy.html\n",
    "train_org = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 \n",
      " ['ID', 'Title', 'Content', 'Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n"
     ]
    }
   ],
   "source": [
    "Total_Samples = len(train.index) # train.shape[0] # both work, but len(train.index) is faster\n",
    "cat = list(train.columns.values)\n",
    "print(Total_Samples, \"\\n\", cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = train.iloc[:, 3:].values # get the values of the labels in matrix form\n",
    "'''\n",
    "matrix = np.array( # for testing\n",
    "    [[0, 0, 1], \n",
    "     [1, 1, 0], \n",
    "     [1, 0, 0]]\n",
    ")\n",
    "'''\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 8\n",
      "init_matrix:\n",
      " [[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "iteration: 4\n",
      "iteration: 5\n",
      "iteration: 6\n",
      "iteration: 7\n",
      "iteration: 8\n",
      "iteration: 9\n",
      "iteration: 10\n",
      "iteration: 11\n",
      "matrix2:\n",
      " [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Randomize matrix keeping row and column totals the same\n",
    "# https://stackoverflow.com/questions/2133268/randomize-matrix-in-perl-keeping-row-and-column-totals-the-same\n",
    "\n",
    "def shuffle(array):\n",
    "    i = len(array)\n",
    "    j = 0\n",
    "    for _ in (array):\n",
    "        i -= 1;\n",
    "        j = random.randrange(0, i+1) #int rand($i + 1);\n",
    "        #print('arrary:', array)\n",
    "        #print(f'len(array)={len(array)}, (i, j)=({i}, {j})')\n",
    "        if i != j: \n",
    "            tmp = array[i]\n",
    "            array[i] = array[j]\n",
    "            array[j] = tmp\n",
    "    return array\n",
    "\n",
    "def other_edits(matrix, cell, step, last_j):\n",
    "    # We have succeeded if we've already made 3 edits.\n",
    "    step += 1\n",
    "    if step > 3: \n",
    "        return True\n",
    "\n",
    "    # Determine the roster of next edits to fix the row or\n",
    "    # column total upset by our prior edit.\n",
    "    (i, j) = cell\n",
    "    fixes = []\n",
    "    if (step == 1):\n",
    "        fixes = [[i, x] for x in range(len(matrix[0])) if x != j and not matrix[i][x] ]\n",
    "        fixes = shuffle(fixes)\n",
    "    elif (step == 2):\n",
    "        fixes = [[x, j] for x in range(len(matrix)) if x != i and matrix[x][j]]\n",
    "        fixes = shuffle(fixes)\n",
    "    else:\n",
    "        # On the last edit, the column of the fix must be\n",
    "        # the same as the column of the initial edit.\n",
    "        if not matrix[i][last_j]: fixes = [[i, last_j]]\n",
    "\n",
    "    for f in (fixes):\n",
    "        # If all subsequent fixes succeed, we are golden: make\n",
    "        # the current fix and return true.\n",
    "        if ( other_edits(matrix, f, step, last_j) ):\n",
    "            matrix[f[0]][f[1]] = 0 if step == 2 else 1\n",
    "            return True\n",
    "\n",
    "    # Failure if we get here.\n",
    "    return False # return False\n",
    "\n",
    "def cells_to_move(matrix):\n",
    "    # Returns a list of non-empty cells.\n",
    "    i = -1\n",
    "    cells = []\n",
    "    for row in matrix:\n",
    "        i += 1;\n",
    "        for j in range(len(row)):\n",
    "            if matrix[i][j]: cells.append([i, j])\n",
    "    return cells\n",
    "\n",
    "def edit_matrix(matrix):\n",
    "    # Takes a matrix and moves all of the non-empty cells somewhere else.\n",
    "    move_these = cells_to_move(matrix)\n",
    "    for cell in move_these:\n",
    "        (i, j) = cell\n",
    "        # Move the cell, provided that the cell hasn't been moved\n",
    "        # already and the subsequent edits don't lead to a dead end.\n",
    "        if matrix[i][j] and other_edits(matrix, cell, 0, j):\n",
    "            matrix[i][j] = 0\n",
    "    return matrix\n",
    "\n",
    "def init_matrix(rows, cols, density): # not used\n",
    "    matrix = []\n",
    "    for r in range(rows):\n",
    "        matrix.append([ 1 if random.random() < density else 0  for _ in range(cols) ])\n",
    "    return matrix\n",
    "\n",
    "def Shuffle_Matrix(matrix, N, M, n_iter):\n",
    "    #matrix = init_matrix(N, M, density)\n",
    "    print(\"init_matrix:\\n\", matrix);\n",
    "    for n in range(n_iter):\n",
    "        print(f'iteration: {n+1}') # Show progress.\n",
    "        matrix = edit_matrix(matrix)\n",
    "        #print('matrix:\\n', matrix)\n",
    "    return matrix\n",
    "\n",
    "def compute_density(train_org, cat):\n",
    "    sum = 0\n",
    "    for category in cat[3:]:\n",
    "        sum += train_org[category].sum()\n",
    "    density = sum/(train_org.shape[0] * train_org.shape[1])\n",
    "    print(f'sum={sum}, density={density}')\n",
    "    return density\n",
    "\n",
    "print(matrix.shape[0], matrix.shape[1]) #;print(matrix)\n",
    "#density = compute_density(train_org, cat)\n",
    "#density = sum([sum(row) for row in matrix])/(matrix.shape[0] * matrix.shape[1])\n",
    "#print('density : %1.6f'%density)\n",
    "\n",
    "# Args: N rows, N columns, density, N iterations.\n",
    "matrix2 = Shuffle_Matrix(matrix, matrix.shape[0], matrix.shape[1], 11) \n",
    "# even n_iter number would be the same for the toy 3x3 example\n",
    "# n_iter =  1, both==380, 370\n",
    "# n_iter =  5, both==349, 363, 371, 402, 390, 401, 371, 366, 381, 373, 389, 410, 384\n",
    "# n_iter = 10, both==381, 392, 393, 364, 402, 399, 406, 386, 380\n",
    "# n_iter = 11, both==350, 364, 362\n",
    "# n_iter = 20, both==374, 356, 368\n",
    "# n_iter = 21, both==396, 337, 379, 368\n",
    "# n_iter = 30, both==384, 379\n",
    "print(\"matrix2:\\n\", matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matrix2 to train\n",
    "j = -1\n",
    "for c in cat[3:]:\n",
    "    j += 1\n",
    "    for i in range(Total_Samples):\n",
    "        train.at[i, c] = matrix2[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both          362\n",
      "right_only      0\n",
      "left_only       0\n",
      "Name: _merge, dtype: int64\n",
      "right_only    1329\n",
      "left_only     1329\n",
      "both             0\n",
      "Name: _merge, dtype: int64\n",
      "1691 362 1329 1329\n",
      "1691 0.21407451212300413\n"
     ]
    }
   ],
   "source": [
    "def dataframe_difference(df1, df2, which=None):\n",
    "    \"\"\"Find rows which are different between two DataFrames.\"\"\"\n",
    "    comparison_df = df1.merge(df2,\n",
    "                              indicator=True,\n",
    "                              how='outer')\n",
    "    if which is None:\n",
    "        diff_df = comparison_df[comparison_df['_merge'] != 'both']\n",
    "    else:\n",
    "        diff_df = comparison_df[comparison_df['_merge'] == which]\n",
    "    #diff_df.to_csv('data/diff.csv')\n",
    "    return diff_df\n",
    "\n",
    "diff_both = dataframe_difference(train_org, train, which='both')\n",
    "both=diff_both['_merge'].value_counts(); print(both)\n",
    "diff = dataframe_difference(train_org, train)\n",
    "one = diff['_merge'].value_counts(); print(one)\n",
    "print(train.shape[0], both['both'], one['right_only'], one['left_only'])\n",
    "print(both['both']+one['right_only'], both['both']/train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  0\n",
      "Title               0\n",
      "Content             0\n",
      "Pun                 0\n",
      "Exaggeration        0\n",
      "Anthropomorphism    0\n",
      "Bridge_Inference    0\n",
      "Illogical           0\n",
      "Irony               0\n",
      "Imitation           0\n",
      "Others              0\n",
      "dtype: int64 \n",
      "\n",
      "ID                  0\n",
      "Title               0\n",
      "Content             0\n",
      "Pun                 0\n",
      "Exaggeration        0\n",
      "Anthropomorphism    0\n",
      "Bridge_Inference    0\n",
      "Illogical           0\n",
      "Irony               0\n",
      "Imitation           0\n",
      "Others              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = train_org.isnull().sum()\n",
    "print(missing_values_check, \"\\n\")\n",
    "missing_values_check = train.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s} = \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Total number of train_org jokes =  1691\n",
      "Number of clean jokes in train_org =  2\n",
      "Number of train_org jokes with labels = 1689\n",
      "\n",
      "Total number of train jokes =  1691\n",
      "Number of clean jokes in train =  2\n",
      "Number of train jokes with labels = 1689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_org.equals(train))\n",
    "print_empty_label(train_org, 'train_org')\n",
    "print_empty_label(train, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n",
      "['Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[3:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of jokes in each category\n",
    "def print_category_count(df, categories):\n",
    "    counts = []\n",
    "    for category in categories:\n",
    "        counts.append((category, df[category].sum()))\n",
    "    df_stats = pd.DataFrame(counts, columns=['category', 'number of jokes'])\n",
    "    print(df_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category  number of jokes\n",
      "0               Pun             1039\n",
      "1      Exaggeration              131\n",
      "2  Anthropomorphism              180\n",
      "3  Bridge_Inference              607\n",
      "4         Illogical              924\n",
      "5             Irony               82\n",
      "6         Imitation              258\n",
      "7            Others              588\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              778\n",
      "1      Exaggeration               71\n",
      "2  Anthropomorphism              140\n",
      "3  Bridge_Inference              316\n",
      "4         Illogical              438\n",
      "5             Irony               47\n",
      "6         Imitation              148\n",
      "7            Others              110\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              778\n",
      "1      Exaggeration               71\n",
      "2  Anthropomorphism              140\n",
      "3  Bridge_Inference              316\n",
      "4         Illogical              438\n",
      "5             Irony               47\n",
      "6         Imitation              148\n",
      "7            Others              110\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              261\n",
      "1      Exaggeration               60\n",
      "2  Anthropomorphism               40\n",
      "3  Bridge_Inference              291\n",
      "4         Illogical              486\n",
      "5             Irony               35\n",
      "6         Imitation              110\n",
      "7            Others              478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_category_count(df, categories)\n",
    "print_category_count(train_org, categories)\n",
    "print_category_count(train, categories)\n",
    "print_category_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df.iloc[:,3:].sum().values)\n",
    "\n",
    "    plt.title(\"Jokes in each category\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Joke Skill', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df.iloc[:,3:].sum().values\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_category_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Calculating number of jokes having multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_label(mlc_labels, multiLabel_counts):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax = sns.barplot(mlc_labels, multiLabel_counts.values)\n",
    "\n",
    "    plt.title(\"Jokes having multiple labels \")\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = multiLabel_counts.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_multiple_label(df):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    multiLabel_counts = rowSums.value_counts()\n",
    "    print(multiLabel_counts)\n",
    "    multiLabel_counts = multiLabel_counts.iloc[:]\n",
    "    #print(multiLabel_counts.index)\n",
    "    mlc_labels = ['L'+str(i) for i in multiLabel_counts.index]\n",
    "    print(mlc_labels)\n",
    "    \n",
    "    #plot_multiple_label(mlc_labels, multiLabel_counts)\n",
    "    ##return(mlc_labels, multiLabel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2964\n",
      "2     355\n",
      "3      41\n",
      "4       3\n",
      "0       2\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L3', 'L4', 'L0']\n",
      "1    1376\n",
      "2     270\n",
      "3      40\n",
      "4       3\n",
      "0       2\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L3', 'L4', 'L0']\n",
      "1    1376\n",
      "2     270\n",
      "3      40\n",
      "4       3\n",
      "0       2\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L3', 'L4', 'L0']\n"
     ]
    }
   ],
   "source": [
    "print_multiple_label(df)\n",
    "print_multiple_label(train_org)\n",
    "print_multiple_label(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the result to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outp_path, 'w') as outF:\n",
    "    outF.write(train.to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
