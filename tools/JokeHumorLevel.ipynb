{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression/Machine for Humorous Level Prediction\n",
    "\n",
    "This program is modified from https://github.com/nkartik94/Multi-Label-Text-Classification\n",
    "on 2019/11/18 by Yuen-Hsien Tseng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sam/GoogleDrive/指導的學生/2019_吳玟萱/2019_1104_Joke_Datasets\r\n"
     ]
    }
   ],
   "source": [
    "!cd /Users/sam/GoogleDrive/指導的學生/2019_吳玟萱/2019_1104_Joke_Datasets\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"mlabel_corpora/JokeHumorLevel.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 4)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "#data_raw = df.loc[np.random.choice(data_raw.index, size=2000)]\n",
    "print(df.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 4)\n",
      "(1674, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ID=L1850 為分界，之前：吳玟萱，之後：黃亭筠，均為中文系同一屆\n",
    "train, test = train_test_split(df, train_size=1691, shuffle=False) \n",
    "# (tempararily) set global variables: train, test \n",
    "\n",
    "with open('mlabel_corpora/JokeHumorLevel_train.txt', 'w') as outF:\n",
    "    outF.write(train.to_csv(sep='\\t', index=False))\n",
    "\n",
    "with open('mlabel_corpora/JokeHumorLevel_test.txt', 'w') as outF:\n",
    "    outF.write(test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf[\\'Content\\'] = df[df.columns[1:3]].apply(\\n    lambda x: \\' 。 \\'.join(x.dropna().astype(str)),\\n    axis=1\\n)\\nprint(\"Number of rows in data =\",df.shape[0])\\nprint(\"Number of columns in data =\",df.shape[1])\\nprint(\"\\n\")\\nprintmd(\"**Sample data:**\")\\ndf.head()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not do this, because there are many duplicate titles\n",
    "# Merge Title into Content\n",
    "'''\n",
    "df['Content'] = df[df.columns[1:3]].apply(\n",
    "    lambda x: ' 。 '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Number of rows in data =\",df.shape[0])\n",
    "print(\"Number of columns in data =\",df.shape[1])\n",
    "print(\"\\n\")\n",
    "printmd(\"**Sample data:**\")\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID            0\n",
      "Title         0\n",
      "Content       0\n",
      "HumorLevel    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = df.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s}= \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all jokes =  3365\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 3365\n",
      "\n",
      "Total number of all jokes =  1691\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1691\n",
      "\n",
      "Total number of all jokes =  1674\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_empty_label(df, 'all')\n",
    "print_empty_label(train, 'train')\n",
    "print_empty_label(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'HumorLevel']\n",
      "['HumorLevel']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[3:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of humor levels \n",
    "# https://stackoverflow.com/questions/45759966/counting-unique-values-in-a-column-in-pandas-dataframe-like-in-qlik\n",
    "def print_HumorLevel_count(df, categories):\n",
    "    for c in categories:\n",
    "        print(df[c].value_counts())\n",
    "        #print(df[c].value_counts(normalize=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    1313\n",
      "2     867\n",
      "4     729\n",
      "1     363\n",
      "5      93\n",
      "Name: HumorLevel, dtype: int64\n",
      "\n",
      "3    742\n",
      "4    604\n",
      "2    251\n",
      "5     47\n",
      "1     47\n",
      "Name: HumorLevel, dtype: int64\n",
      "\n",
      "2    616\n",
      "3    571\n",
      "1    316\n",
      "4    125\n",
      "5     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_HumorLevel_count(df, categories)\n",
    "print_HumorLevel_count(train, categories)\n",
    "print_HumorLevel_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not correct yet!!!\n",
    "def plot_HumorLevel_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df[categories[0]].value_counts())\n",
    "\n",
    "    plt.title(\"Humorous Level Count\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Humorous Level', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df[categories[0]].value_counts()\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_HumorLevel_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in   all jokes: Max=2024, Min=10, Avg=134.07637444279345\n",
      "Number of characters in train jokes: Max=2024, Min=10, Avg=132.7906564163217\n",
      "Number of characters in  test jokes: Max=874, Min=12, Avg=135.3751493428913\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = df.Content.map(len)\n",
    "print(f'Number of characters in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(len)\n",
    "print(f'Number of characters in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(len)\n",
    "print(f'Number of characters in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set global variables: data\n",
    "data = df\n",
    "#data = df.loc[np.random.choice(df.index, size=3365)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stopwords # import my own module with STOP_WORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    Given a raw text string, return a clean text string.\n",
    "    Example: \n",
    "        input:  \"Years  passed. 多少   年过 去 了 。  \"\n",
    "        output: \"years passed.多少年过去了。\"\n",
    "    '''\n",
    "    text = str(text)\n",
    "    text = text.lower() # 'years  passed. 多少   年过 去 了 。'\n",
    "    # Next line will remove redundant white space for jeiba to cut\n",
    "    text = re.sub(r'\\s+([^a-zA-Z0-9.])', r'\\1', text) # years passed.多少年过去了。\n",
    "# see: https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_words(text, RmvStopWord=True, RmvMark=True):\n",
    "    words = jieba.lcut(text)\n",
    "#    print(\"After jieba.lcut():\", words)\n",
    "#    WL = [ w \n",
    "    WL = [ ps.stem(w)\n",
    "#    WL = [ wnl.lemmatize(w)\n",
    "        for w in words \n",
    "          if (not re.match(r'\\s', w)) # remove white spaces\n",
    "            and (RmvMark==False or not re.match(r'\\W', w)) # remove punctuations\n",
    "#            and (RmvMark==False or not re.match('^[a-z_]$', w)) # remove punctuations\n",
    "#            and (RmvMark==False or w not in PUNCTUATIONS)\n",
    "            and (RmvStopWord==False or w not in Stopwords.STOP_WORDS)\n",
    "            and (not re.match(r'^\\d+$', w)) # remove digit\n",
    "         ]\n",
    "    WL = \" \".join(WL)\n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/kg/jcdj05xn20144cv9kwywp26r0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Title                                            Content  HumorLevel\n",
      "0  L0001  要求加薪  員工：老闆，您必須幫我加薪，已經有三家公司在找我了！     老闆：哪三家？     員工：...           4\n",
      "1  L0002  查無此人  某市政府辦公大樓落成，門口缺副對聯。     副市長揮毫     上聯：說實話辦實事一身正氣...           3\n",
      "2  L0003   遣散費  中午老闆視察自己的建築工地時，發現有個人在角落玩手機。     老闆：你月薪多少？     ...           4\n",
      "3  L0004  職業習慣  一天，一位法官的女友看見兩個蚊子，便叫法官打死。     只見法官只把那個肚子飽飽的蚊子打死...           2\n",
      "4  L0005  美女吵架  辦公室中兩位女同事吵起來了。     經理忍無可忍：「太不像話了！現在是什麼情況？你們把原因...           4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.630 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data['Content'] = data['Content'].str.lower()\n",
    "#data['Content'] = data['Content'].apply(cleanHtml)\n",
    "#data['Content'] = data['Content'].apply(cleanPunc)\n",
    "#data['Content'] = data['Content'].apply(keepAlpha)\n",
    "data['Content'] = data['Content'].apply(clean_text)\n",
    "data['Content'] = data['Content'].apply(clean_words)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['Content'] = data['Content'].apply(removeStopWords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>HumorLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0001</td>\n",
       "      <td>要求加薪</td>\n",
       "      <td>員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0002</td>\n",
       "      <td>查無此人</td>\n",
       "      <td>某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0003</td>\n",
       "      <td>遣散費</td>\n",
       "      <td>中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0004</td>\n",
       "      <td>職業習慣</td>\n",
       "      <td>一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0005</td>\n",
       "      <td>美女吵架</td>\n",
       "      <td>辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Title                                            Content  HumorLevel\n",
       "0  L0001  要求加薪  員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...           4\n",
       "1  L0002  查無此人  某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...           3\n",
       "2  L0003   遣散費  中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...           4\n",
       "3  L0004  職業習慣  一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...           2\n",
       "4  L0005  美女吵架  辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...           4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['Content'] = data['Content'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 4)\n",
      "(1674, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set global variables: train, test\n",
    "#train, test = train_test_split(data, random_state=42, test_size=0.10, shuffle=True)\n",
    "train, test = train_test_split(data, random_state=42, train_size=1691, shuffle=False)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables: train_text, test_text\n",
    "train_text = train['Content']\n",
    "test_text = test['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in   all jokes: Max=491, Min=3, Avg=41.6222882615156\n",
      "Number of words in train jokes: Max=491, Min=3, Avg=40.33234772324069\n",
      "Number of words in  test jokes: Max=290, Min=4, Avg=42.92532855436081\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = data.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables:\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['ID', 'Title', 'Content'], axis=1)\n",
    "#print(y_train.head())\n",
    "train_yL = y_train['HumorLevel']\n",
    "#print(type(train_yL), \"\\n\", train_yL.head())\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['ID', 'Title', 'Content'], axis=1)\n",
    "test_yL = y_test['HumorLevel']\n",
    "\n",
    "# label encode the target variable \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "LabEncoder = preprocessing.LabelEncoder() # convert label name to label int\n",
    "train_y = LabEncoder.fit_transform(train_yL)\n",
    "test_y = LabEncoder.fit_transform(test_yL)\n",
    "Num_Classes = len(LabEncoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_tfidf.shape:(1691, 10000), xtest_tfidf.shape: (1674, 10000)\n",
      "xtrain_tfidf_ngram.shape:(1691, 10000), xtest_tfidf_ngram.shape: (1674, 10000)\n",
      "xtrain_tfidf_ngram_chars.shape:(1691, 10000), xtest_tfidf_ngram_chars.shape: (1674, 10000)\n",
      "It takes 3.24 seconds to convert 3 TFxIDF vectors.\n"
     ]
    }
   ],
   "source": [
    "time_TfidfVector = time.time()\n",
    "\n",
    "def Create_TFxIDF(data_text, train_text, test_text):\n",
    "\n",
    "# word level tf-idf\n",
    "    #tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=1, max_features=10000)\n",
    "    tfidf_vect.fit(data_text)\n",
    "    xtrain_tfidf = tfidf_vect.transform(train_text)\n",
    "    xtest_tfidf = tfidf_vect.transform(test_text)\n",
    "    print(f\"xtrain_tfidf.shape:{xtrain_tfidf.shape}, xtest_tfidf.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# word level ngram tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=1,\n",
    "                    ngram_range=(1,3), max_features=10000)\n",
    "    tfidf_vect_ngram.fit(data_text)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    print(f\"xtrain_tfidf_ngram.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# character level ngram tf-idf\n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=1,\n",
    "                    ngram_range=(1,3), max_features=10000)\n",
    "    tfidf_vect_ngram_chars.fit(data_text)\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "    xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) \n",
    "    print(f\"xtrain_tfidf_ngram_chars.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram_chars.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert 3 TFxIDF vectors.\"%(time.time()-time_TfidfVector))\n",
    "\n",
    "    return (xtrain_tfidf, xtest_tfidf, \n",
    "             xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    "             xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    "            tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars)\n",
    "\n",
    "# Set global variables:\n",
    "(xtrain_tfidf, xtest_tfidf, \n",
    " xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    " xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    " tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars) = Create_TFxIDF(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 62330) (1674, 62330)\n"
     ]
    }
   ],
   "source": [
    "# re-assign x_train and x_test to what we want\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf, xtest_tfidf, tfidf_vect\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram, xtest_tfidf_ngram, tfidf_vect_ngram\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars, tfidf_vect_ngram_chars\n",
    "print(x_train.shape, x_test.shape)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 0.27 seconds to convert count vectors.\n"
     ]
    }
   ],
   "source": [
    "time_CountVector = time.time()\n",
    "\n",
    "def Create_CountVector(data_text, train_text, test_text):\n",
    "\n",
    "# Create a count vectorizer object.\n",
    "# It takes the steps of prepocessing, tokenizer, stopwording, ...\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "    count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=1)\n",
    "    count_vect.fit(data_text)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "    xtrain_count = count_vect.transform(train_text)\n",
    "    xtest_count = count_vect.transform(test_text)\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert count vectors.\"%(time.time()-time_CountVector))\n",
    "\n",
    "    return(xtrain_count, xtest_count, count_vect)\n",
    "\n",
    "# Set global variables:\n",
    "(xtrain_count, xtest_count, count_vect) = Create_CountVector(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'> CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=['的', '是', '了', '和', '與', '及', '或', '於', '也', '並', '之', '以', '在', '另', '又', '該', '由', '但', '仍', '就', '都', '讓', '要', '把', '上', '來', '說', '從', '等', '我', '你', '他', '妳', '她', '它', '您', '我們', '你們', '妳們', '他們', '她們', '有', '此', '因', '且', '為', '嗎', '那', '哪', '吧', '很', '這', '並有', '並可', '可以', '可供',...ithin', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', 'said', 'told'],\n",
      "        strip_accents=None, token_pattern='\\\\w{1,}', tokenizer=None,\n",
      "        vocabulary=None)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n",
      "xtrain_count.shape: (1691, 28013)\n",
      "xtest_count.shape : (1674, 28013)\n",
      "\n",
      "Used stop words:  frozenset({'eight', 'off', 'ltd', 'hereby', 'been', 'we', 'so', '讓', '您', '與', 'all', 'she', 'most', 'keep', '了', 'seemed', 'around', 'take', 'beforehand', 'is', 'your', 'full', 'nor', 'interest', 'afterwards', 'already', 'while', 'and', 'down', '我們', '另外', 'con', 'its', '此外', 'seem', 'before', '有', 'move', '但', 'sixty', 'be', '那', 'between', '哪', 'hence', 'behind', 'by', 'it', 'others', 'become', 'also', 'anyone', 'co', '是', 'themselves', '的', 'much', 'across', '可能', '另', 'hasnt', 'where', 'amoungst', 'am', 'un', 'etc', 'cannot', 'show', 'although', 'if', 'any', 'whether', 'below', 'often', 'nothing', 'until', 'ourselves', 'everything', 'thus', 'same', 'third', '從', '為', 'thru', 'de', 'he', '除了', 'too', 'per', 'rather', 'very', 'mine', '你', 'top', '並可', 'onto', '它', 'told', 'fill', 'sometime', 'though', 'always', 'a', 'eg', '於', 'has', 'over', '上', '他', 'the', 'yourself', '和', 'former', 'give', '且', 'yourselves', 'done', 'could', '仍', 'meanwhile', 'more', 'bottom', 'sincere', 'can', 'less', 'how', 'other', 'anyway', 'at', '⒈', 'cant', 'this', 'one', 'hereafter', 'as', 'us', '要', 'those', '他們', '由', 'inc', 'ten', 'about', 'being', 'who', 'had', 'whereas', 'seems', 'toward', 'amongst', '她', 'itself', 'well', 'whom', 'mostly', 'go', 'neither', 'moreover', 'eleven', 'since', 'namely', 'out', 'even', '也', 'from', '提供', '這麼', 'via', 'they', 'anyhow', 'indeed', '該', 'me', 'within', '以', 'found', 'our', 'anywhere', '可供', 'three', 'everywhere', '她們', '並有', '⒉', 'twenty', 'nevertheless', 'now', 'an', '它會', 'against', 'such', 'couldnt', 'towards', '並', 'cry', 'either', 'another', 'my', 'upon', 'along', 'except', 'you', 'why', 'here', 'only', 'hereupon', 'was', 'six', 'never', '你們', '吧', 'said', 'wherever', 'name', 'under', '這', 'because', '妳', 'front', 'some', 'his', '妳們', 'put', 'everyone', 'forty', 'myself', 'alone', 'therein', 'might', 'find', 'noone', 'whatever', 'her', 'on', 'two', 'almost', 'with', 'whose', '因為', 'together', 'nowhere', 'every', 'fifteen', 'into', 'few', '很', '另有', 'what', 'hers', 'throughout', 'in', '及', 'sometimes', 'whence', 'whereby', '就', 'their', 'ours', 'among', '仍就', '⒊', '那些', 'please', 'were', 'several', 'each', 'somewhere', 'that', 're', 'himself', 'mill', 'without', 'twelve', 'further', 'may', '現在', '都', 'these', '以及', 'not', 'due', 'up', 'becomes', 'describe', 'next', '因', '或', 'have', 'none', 'whoever', 'system', '之', 'but', 'detail', 'do', 'see', '圖上', '就是', 'yet', 'beside', 'ie', 'than', 'again', 'them', 'thereafter', 'becoming', 'i', '把', 'fire', 'beyond', 'after', 'serious', 'last', 'five', '此', 'own', '則是', 'empty', 'least', 'made', 'thick', 'many', 'first', 'thin', 'four', 'once', 'then', 'whenever', 'whole', 'elsewhere', 'during', '說', 'formerly', 'through', 'nobody', 'someone', 'therefore', 'still', 'of', 'however', 'thence', 'when', 'thereupon', 'or', '可以', '應該', 'no', 'wherein', 'ever', 'both', 'anything', 'get', 'perhaps', 'call', 'should', 'besides', 'whither', '等', 'side', '嗎', 'which', 'herein', '在', 'to', 'for', 'yours', 'latterly', 'will', 'must', 'there', '我', 'nine', 'whereafter', 'above', 'enough', 'hundred', 'part', 'otherwise', 'somehow', 'something', 'fifty', '什麼', 'bill', 'seeming', '包括', 'became', 'would', 'him', 'latter', 'thereby', 'are', 'amount', 'herself', 'else', '目前', 'back', '來', 'whereupon', '又'})\n"
     ]
    }
   ],
   "source": [
    "def Print_count_vect(xtrain_count, xtest_count, count_vect):\n",
    "    print(type(count_vect), count_vect)\n",
    "    print(type(xtrain_count), type(xtest_count))\n",
    "    print(\"xtrain_count.shape:\", xtrain_count.shape)\n",
    "    print(\"xtest_count.shape :\", xtest_count.shape)\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "# from scipy.sparse.csr import csr_matrix\n",
    "    # A = csr_matrix([[1, 0, 2], [0, 3, 0]]); print(A)\n",
    "    # df = pd.DataFrame(A.toarray()); print(df)\n",
    "    #print(xtrain_count)\n",
    "    #print(xtest_count[0, 0:10])\n",
    "    print(\"\\nUsed stop words: \", count_vect.get_stop_words())\n",
    "    \n",
    "Print_count_vect(xtrain_count, xtest_count, count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "from sklearn.metrics import explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def print_svr_report(y_true, prediction):\n",
    "    #print('max_error: %1.4f'%(max_error(y_true, prediction)))\n",
    "    print('mean_squared_error: %1.4f'%(mean_squared_error(y_true, prediction)))\n",
    "    print('mean_absolute_error: %1.4f'%(mean_absolute_error(y_true, prediction)))\n",
    "    print('r2_score: %1.4f'%(r2_score(y_true, prediction)))\n",
    "    print('explained_variance_score: %1.4f'%(explained_variance_score(y_true, prediction)))\n",
    "\n",
    "    print(f'y_true.shape={y_true.shape}, prediction.shape={prediction.shape}')\n",
    "    #type(y_true<class 'pandas.core.frame.DataFrame'>, type(prediction)=<class 'numpy.ndarray'>\n",
    "    print(f'type(y_true{type(y_true)}, type(prediction)={type(prediction)}')\n",
    "\n",
    "    #pred = pd.DataFrame(data=prediction, columns=[y_true.columns]) # cannot have the same column name with y_true\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "    pred = pd.DataFrame(data=y_true.reset_index(drop=True), columns=['HumorLevel'])\n",
    "    pred['Funiness'] = prediction\n",
    "    pred['FuninessLevel'] = pred['Funiness'].map(round)\n",
    "    #print('y_true.head() :\\n', y_true.head())\n",
    "    print('pred.head() :\\n', pred.head())\n",
    "\n",
    "    print(y_true[y_true.columns[0]].value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "    print(pred.FuninessLevel.value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "# https://stackoverflow.com/questions/52777668/python-pandas-compare-two-columns-for-equality-and-result-in-third-dataframe\n",
    "    pred['result'] = np.where(pred['HumorLevel'] == pred['FuninessLevel'], 1, 0)\n",
    "    print(pred['result'].value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "    print(pred['result'].value_counts(normalize=True, sort=False, ascending=False, bins=None, dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next line refers to: http://scikit.ml/tutorial.html\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "# Next line refers to https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg.score: 0.992050752320993\n",
      "mean_squared_error: 1.8555\n",
      "mean_absolute_error: 1.1269\n",
      "r2_score: -0.9988\n",
      "explained_variance_score: -0.1625\n",
      "y_true.shape=(1674, 1), prediction.shape=(1674, 1)\n",
      "type(y_true<class 'pandas.core.frame.DataFrame'>, type(prediction)=<class 'numpy.ndarray'>\n",
      "pred.head() :\n",
      "    HumorLevel  Funiness  FuninessLevel\n",
      "0           5  2.828638              3\n",
      "1           4  3.108231              3\n",
      "2           4  3.270776              3\n",
      "3           4  3.490234              3\n",
      "4           4  3.320486              3\n",
      "1    316\n",
      "2    616\n",
      "3    571\n",
      "4    125\n",
      "5     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "2      41\n",
      "3    1197\n",
      "4     433\n",
      "5       2\n",
      "7       1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1227\n",
      "1     447\n",
      "Name: result, dtype: int64\n",
      "0    0.732975\n",
      "1    0.267025\n",
      "Name: result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "print(\"reg.score:\", reg.score(x_train, y_train))\n",
    "predictions = reg.predict(x_test)\n",
    "print_svr_report(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 1.6650\n",
      "mean_absolute_error: 1.0614\n",
      "r2_score: -0.7936\n",
      "explained_variance_score: -0.0319\n",
      "y_true.shape=(1674, 1), prediction.shape=(1674,)\n",
      "type(y_true<class 'pandas.core.frame.DataFrame'>, type(prediction)=<class 'numpy.ndarray'>\n",
      "pred.head() :\n",
      "    HumorLevel  Funiness  FuninessLevel\n",
      "0           5  2.831474              3\n",
      "1           4  3.316667              3\n",
      "2           4  3.105655              3\n",
      "3           4  3.274082              3\n",
      "4           4  3.372976              3\n",
      "1    316\n",
      "2    616\n",
      "3    571\n",
      "4    125\n",
      "5     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "3    1509\n",
      "4     165\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1145\n",
      "1     529\n",
      "Name: result, dtype: int64\n",
      "0    0.68399\n",
      "1    0.31601\n",
      "Name: result, dtype: float64\n",
      "CPU times: user 89.3 ms, sys: 2.34 ms, total: 91.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "classifier = LinearSVR()\n",
    "classifier.fit(x_train, y_train)\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "print_svr_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error: 1.4409\n",
      "mean_absolute_error: 0.9547\n",
      "r2_score: -0.5521\n",
      "explained_variance_score: 0.0000\n",
      "y_true.shape=(1674, 1), prediction.shape=(1674,)\n",
      "type(y_true<class 'pandas.core.frame.DataFrame'>, type(prediction)=<class 'numpy.ndarray'>\n",
      "pred.head() :\n",
      "    HumorLevel  Funiness  FuninessLevel\n",
      "0           5  3.100021              3\n",
      "1           4  3.100055              3\n",
      "2           4  3.100031              3\n",
      "3           4  3.100032              3\n",
      "4           4  3.100041              3\n",
      "1    316\n",
      "2    616\n",
      "3    571\n",
      "4    125\n",
      "5     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "3    1674\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1103\n",
      "1     571\n",
      "Name: result, dtype: int64\n",
      "0    0.658901\n",
      "1    0.341099\n",
      "Name: result, dtype: float64\n",
      "CPU times: user 1.01 s, sys: 13 ms, total: 1.02 s\n",
      "Wall time: 669 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "classifier = SVR()\n",
    "classifier.fit(x_train, y_train)\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "print_svr_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/HumorLevel_True.txt', 'w') as outF:\n",
    "    outF.write(y_test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "with open('out/HumorLevel_Pred.txt', 'w') as outF:\n",
    "    outF.write(pd.DataFrame(predictions, columns=list(y_test.columns)).to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. use classification for prediction Humorous Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(classifier, feature_vector_train, label, feature_vector_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    # predict the labels on test dataset\n",
    "    return classifier.predict(feature_vector_test), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcfunc(x, n=4): # trancate a number to have n decimal digits\n",
    "    d = '0' * n\n",
    "    d = int('1' + d)\n",
    "# https://stackoverflow.com/questions/4541155/check-if-a-number-is-int-or-float\n",
    "    if isinstance(x, (int, float)): return int(x * d) / d\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "#import itertools # replace this line by next line on 2019/01/03, because cannot find itertools for Python 3.6.7\n",
    "import more_itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm) # print out consufion matrix\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "#    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "# Replace the above line by the next line on 2019/01/03, because cannot find itertools for Python 3.6.7\n",
    "    for i, j in more_itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use global variables:\n",
    "#  test_y\n",
    "#  LabEncoder.classes_\n",
    "def show_confusion_matrix(predictions):\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(test_y, predictions)\n",
    "    numpy.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=LabEncoder.classes_ ,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=LabEncoder.classes_ , normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# use a global variable: test_y\n",
    "def show_Result(predictions):\n",
    "    print(predictions[:10])\n",
    "\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "#    print(\"MicroF1 = %0.4f, MacroF1=%0.4f\" %\n",
    "#       (metrics.f1_score(test_y, predictions, average='micro'),\n",
    "#        metrics.f1_score(test_y, predictions, average='macro')))\n",
    "# https://stackoverflow.com/questions/455612/limiting-floats-to-two-decimal-points\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"\\tPrecision\\tRecall\\tF1\\tSupport\")\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(test_y, predictions, average='micro')))\n",
    "    print(\"Micro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(test_y, predictions, average='macro')))\n",
    "    print(\"Macro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    \n",
    "    if True:\n",
    "    #if False:\n",
    "        print(confusion_matrix(test_y, predictions))\n",
    "        try: \n",
    "            print(classification_report(test_y, predictions, digits=4))\n",
    "        except ValueError:\n",
    "            print('May be some category has no predicted samples')\n",
    "        show_confusion_matrix(predictions)\n",
    "\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "    y_true = pd.DataFrame(test_y, columns=['HumorLevel'])\n",
    "    pred = pd.DataFrame(data=y_true.reset_index(drop=True), columns=['HumorLevel'])\n",
    "    pred['FuninessLevel'] = predictions\n",
    "    \n",
    "    print(y_true[y_true.columns[0]].value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "    print(pred.FuninessLevel.value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "# https://stackoverflow.com/questions/52777668/python-pandas-compare-two-columns-for-equality-and-result-in-third-dataframe\n",
    "    pred['result'] = np.where(pred['HumorLevel'] == pred['FuninessLevel'], 1, 0)\n",
    "    print(pred['result'].value_counts(normalize=False, sort=False, ascending=False, bins=None, dropna=True))\n",
    "    print(pred['result'].value_counts(normalize=True, sort=False, ascending=False, bins=None, dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is modified from: https://gist.github.com/bbengfort/044682e76def583a12e6c09209c664a1\n",
    "# and from: https://stackoverflow.com/questions/26976362/how-to-get-most-informative-features-for-scikit-learn-classifier-for-different-c\n",
    "# This function only works for binary classes\n",
    "def most_informative_feature_for_class(vectorizer, classifier, labels, n=10):\n",
    "    coefs = sorted( # Zip the feature names with the coefs and sort\n",
    "        zip(classifier.coef_[0], vectorizer.get_feature_names()))\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (cp, fnp, cn, fnn))\n",
    "\n",
    "# nltk.classify.NaiveBayesClassifier has a show_most_informative_features()\n",
    "# You may compare the result here with those at: https://www.twilio.com/blog/2017/09/sentiment-analysis-python-messy-data-nltk.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Run classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NB, Count Vectors: \n",
      "[1 3 3 2 3 3 3 3 1 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.1875\t0.1875\t0.1875\tNone\n",
      "Macro\t0.1684\t0.2047\t0.108\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0       2\n",
      "1      22\n",
      "2     640\n",
      "3    1009\n",
      "4       1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1360\n",
      "1     314\n",
      "Name: result, dtype: int64\n",
      "0    0.812425\n",
      "1    0.187575\n",
      "Name: result, dtype: float64\n",
      "\t-10.3078\t0rz            \t\t-7.2167\t去              \n",
      "\t-10.3078\t1              \t\t-7.3633\t不              \n",
      "\t-10.3078\t10             \t\t-7.4174\t到              \n",
      "\t-10.3078\t139            \t\t-7.5352\t老師             \n",
      "\t-10.3078\t14             \t\t-7.5997\t一個             \n",
      "\t-10.3078\t15             \t\t-7.6687\t吃              \n",
      "\t-10.3078\t1500cc         \t\t-7.6687\t人              \n",
      "\t-10.3078\t18             \t\t-7.6687\t一天             \n",
      "\t-10.3078\t1c             \t\t-7.7428\t後              \n",
      "\t-10.3078\t2              \t\t-7.8229\t覺得             \n",
      "\n",
      "NB, WordLevel TF-IDF: \n",
      "[3 3 2 2 3 2 3 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2783\t0.2783\t0.2783\tNone\n",
      "Macro\t0.0875\t0.2132\t0.1228\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "2    1214\n",
      "3     460\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1208\n",
      "1     466\n",
      "Name: result, dtype: int64\n",
      "0    0.721625\n",
      "1    0.278375\n",
      "Name: result, dtype: float64\n",
      "\t-9.2293\t1c             \t\t-8.2425\t女              \n",
      "\t-9.2293\t2              \t\t-8.2786\t男              \n",
      "\t-9.2293\t30             \t\t-8.2963\t老師             \n",
      "\t-9.2293\t32a            \t\t-8.3513\t覺得             \n",
      "\t-9.2293\t3d             \t\t-8.3963\t髮              \n",
      "\t-9.2293\t5              \t\t-8.4872\t小明             \n",
      "\t-9.2293\t_              \t\t-8.4878\t一天             \n",
      "\t-9.2293\t__________     \t\t-8.5268\t去              \n",
      "\t-9.2293\tatr            \t\t-8.5444\t衣服             \n",
      "\t-9.2293\tbabi           \t\t-8.5522\t吃              \n",
      "\n",
      "NB, N-Gram Vectors: \n",
      "[2 3 3 2 3 2 2 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2855\t0.2855\t0.2855\tNone\n",
      "Macro\t0.0893\t0.2186\t0.1258\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "2    1246\n",
      "3     428\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1196\n",
      "1     478\n",
      "Name: result, dtype: int64\n",
      "0    0.714456\n",
      "1    0.285544\n",
      "Name: result, dtype: float64\n",
      "\t-9.2309\t1c             \t\t-8.3353\t女              \n",
      "\t-9.2309\t1c c           \t\t-8.3777\t老師             \n",
      "\t-9.2309\t2              \t\t-8.3911\t男              \n",
      "\t-9.2309\t30             \t\t-8.3996\t覺得             \n",
      "\t-9.2309\t32a            \t\t-8.4790\t髮              \n",
      "\t-9.2309\t3d             \t\t-8.5213\t衣服             \n",
      "\t-9.2309\t5              \t\t-8.5404\t小明             \n",
      "\t-9.2309\t_              \t\t-8.5472\t我家             \n",
      "\t-9.2309\t_ x0008        \t\t-8.5556\t一天             \n",
      "\t-9.2309\t_ x0008 _      \t\t-8.5597\t去              \n",
      "NB, CharLevel Vectors: \n",
      "[3 2 3 2 2 3 3 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2502\t0.2502\t0.2502\tNone\n",
      "Macro\t0.0862\t0.2054\t0.117\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "2    1042\n",
      "3     632\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1255\n",
      "1     419\n",
      "Name: result, dtype: int64\n",
      "0    0.749701\n",
      "1    0.250299\n",
      "Name: result, dtype: float64\n",
      "\t-9.2533\t 3             \t\t-8.3298\t小              \n",
      "\t-9.2533\t _             \t\t-8.3763\t一              \n",
      "\t-9.2533\t _             \t\t-8.3821\t 小             \n",
      "\t-9.2533\t a             \t\t-8.4893\t 一             \n",
      "\t-9.2533\t bo            \t\t-8.5998\t天              \n",
      "\t-9.2533\t c             \t\t-8.6199\t 老師            \n",
      "\t-9.2533\t c             \t\t-8.6309\t家              \n",
      "\t-9.2533\t d             \t\t-8.6327\t老師             \n",
      "\t-9.2533\t e             \t\t-8.6388\t家              \n",
      "\t-9.2533\t e             \t\t-8.6528\t男              \n",
      "\n",
      "It takes 0.12 seconds for Naive Bayes.\n"
     ]
    }
   ],
   "source": [
    "def Run_NaiveBayes():\n",
    "    \n",
    "    time_NaiveBayes = time.time()\n",
    "\n",
    "# Naive Bayes on Count Vectors   \n",
    "    predict, clf = train_predict(naive_bayes.MultinomialNB(), xtrain_count, train_y, xtest_count)\n",
    "    print(\"\\nNB, Count Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(count_vect, clf, train_yL, n=10)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "    predict, clf = train_predict(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "    print(\"\\nNB, WordLevel TF-IDF: \")\n",
    "    show_Result(predict)\n",
    "    #most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10)\n",
    "    most_informative_feature_for_class(tfidf_vect, clf, train_y, n=10)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "    predict, clf = train_predict(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "    print(\"\\nNB, N-Gram Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram, clf, train_y, n=10)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "    predict, clf = train_predict(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "    print(\"NB, CharLevel Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram_chars, clf, train_y, n=10)\n",
    "\n",
    "    print(\"\\nIt takes %4.2f seconds for Naive Bayes.\"%(time.time()-time_NaiveBayes))\n",
    "\n",
    "Run_NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR, Count Vectors: \n",
      "[2 2 2 2 3 2 2 2 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2371\t0.2371\t0.2371\tNone\n",
      "Macro\t0.2603\t0.1974\t0.1269\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0      2\n",
      "1     69\n",
      "2    903\n",
      "3    697\n",
      "4      3\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1277\n",
      "1     397\n",
      "Name: result, dtype: int64\n",
      "0    0.762843\n",
      "1    0.237157\n",
      "Name: result, dtype: float64\n",
      "\t-0.7019\t看              \t\t1.0498\t菜              \n",
      "\t-0.5585\t叫              \t\t1.0457\t覺得             \n",
      "\t-0.5130\t買              \t\t0.8503\t冷              \n",
      "\t-0.4866\t阿              \t\t0.8264\t髮              \n",
      "\t-0.4821\t時候             \t\t0.8253\t隨便             \n",
      "\t-0.4756\t聽              \t\t0.8003\t最紅             \n",
      "\t-0.4690\t答              \t\t0.7731\t番茄             \n",
      "\t-0.4137\t醫生             \t\t0.7526\t衣服             \n",
      "\t-0.4102\t著              \t\t0.7437\t電話響            \n",
      "\t-0.4039\t如果             \t\t0.7389\t好煩             \n",
      "\n",
      "LR, WordLevel TF-IDF: \n",
      "[2 3 3 2 2 2 2 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2467\t0.2467\t0.2467\tNone\n",
      "Macro\t0.1839\t0.1971\t0.1144\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "1       2\n",
      "2    1051\n",
      "3     621\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1261\n",
      "1     413\n",
      "Name: result, dtype: int64\n",
      "0    0.753286\n",
      "1    0.246714\n",
      "Name: result, dtype: float64\n",
      "\t-0.4465\t答              \t\t1.1313\t覺得             \n",
      "\t-0.4035\t看              \t\t1.0271\t髮              \n",
      "\t-0.3699\t叫              \t\t0.7937\t衣服             \n",
      "\t-0.3629\t老婆             \t\t0.7926\t我家             \n",
      "\t-0.3503\t聽              \t\t0.7353\t冷              \n",
      "\t-0.3463\t問              \t\t0.6979\t女              \n",
      "\t-0.3321\t醫生             \t\t0.6956\t爺爺             \n",
      "\t-0.3164\t老              \t\t0.6907\t番茄             \n",
      "\t-0.3091\t時候             \t\t0.6852\t層              \n",
      "\t-0.2830\t媽媽             \t\t0.6823\t隨便             \n",
      "\n",
      "LR, N-Gram Vectors: \n",
      "[2 3 3 2 2 2 2 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2389\t0.2389\t0.2389\tNone\n",
      "Macro\t0.0833\t0.195\t0.1121\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "1       1\n",
      "2    1019\n",
      "3     654\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1274\n",
      "1     400\n",
      "Name: result, dtype: int64\n",
      "0    0.761051\n",
      "1    0.238949\n",
      "Name: result, dtype: float64\n",
      "\t-0.5092\t答              \t\t1.0398\t覺得             \n",
      "\t-0.4341\t問              \t\t0.8905\t髮              \n",
      "\t-0.3698\t看              \t\t0.8472\t衣服             \n",
      "\t-0.3572\t叫              \t\t0.8067\t我家             \n",
      "\t-0.3495\t老婆             \t\t0.6496\t爺爺             \n",
      "\t-0.3247\t聽              \t\t0.6476\t冷              \n",
      "\t-0.3129\t醫生             \t\t0.6393\t番茄             \n",
      "\t-0.2987\t時候             \t\t0.6351\t母              \n",
      "\t-0.2742\t老              \t\t0.6331\t隨便             \n",
      "\t-0.2612\t媽媽             \t\t0.6188\t層              \n",
      "\n",
      "LR, CharLevel Vectors: \n",
      "[2 2 3 2 2 3 3 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2287\t0.2287\t0.2287\tNone\n",
      "Macro\t0.1514\t0.1928\t0.1116\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "1      3\n",
      "2    929\n",
      "3    742\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1291\n",
      "1     383\n",
      "Name: result, dtype: int64\n",
      "0    0.771207\n",
      "1    0.228793\n",
      "Name: result, dtype: float64\n",
      "\t-0.3304\t生              \t\t0.5703\t覺得             \n",
      "\t-0.3274\t媽              \t\t0.5596\t安              \n",
      "\t-0.3267\t 答             \t\t0.5563\t覺得             \n",
      "\t-0.3206\t老              \t\t0.5430\t頭 髮            \n",
      "\t-0.3171\t問              \t\t0.5067\t爺              \n",
      "\t-0.2818\t 答             \t\t0.5007\t覺              \n",
      "\t-0.2701\t生              \t\t0.4597\t 覺得            \n",
      "\t-0.2662\t子              \t\t0.4512\t家              \n",
      "\t-0.2642\t有              \t\t0.4485\t髮              \n",
      "\t-0.2590\t答              \t\t0.4485\t 髮             \n",
      "\n",
      "It takes 0.37 seconds for Logistic Regression.\n"
     ]
    }
   ],
   "source": [
    "def Run_LogisticRegret():\n",
    "    \n",
    "    time_LogisticRegret = time.time()\n",
    "\n",
    "# Linear Classifier on Count Vectors\n",
    "    predict, clf = train_predict(linear_model.LogisticRegression(), xtrain_count, train_y, xtest_count)\n",
    "    print(\"\\nLR, Count Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(count_vect, clf, train_y, n=10)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "    predict, clf = train_predict(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "    print(\"\\nLR, WordLevel TF-IDF: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect, clf, train_y, n=10)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "    predict, clf = train_predict(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "    print(\"\\nLR, N-Gram Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram, clf, train_y, n=10)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "    predict, clf = train_predict(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "    print(\"\\nLR, CharLevel Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram_chars, clf, train_y, n=10)\n",
    "\n",
    "    print(\"\\nIt takes %4.2f seconds for Logistic Regression.\"%(time.time()-time_LogisticRegret))\n",
    "\n",
    "Run_LogisticRegret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM, Count Vectors: \n",
      "[1 3 2 2 3 2 2 3 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2401\t0.2401\t0.2401\tNone\n",
      "Macro\t0.2025\t0.1954\t0.1365\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0     13\n",
      "1    125\n",
      "2    878\n",
      "3    639\n",
      "4     19\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1272\n",
      "1     402\n",
      "Name: result, dtype: int64\n",
      "0    0.759857\n",
      "1    0.240143\n",
      "Name: result, dtype: float64\n",
      "\t-0.3721\t遠              \t\t0.6954\t菜              \n",
      "\t-0.3368\t離              \t\t0.6785\t最紅             \n",
      "\t-0.3323\t最              \t\t0.5201\t好煩             \n",
      "\t-0.3140\t找              \t\t0.5201\t太美             \n",
      "\t-0.2881\t買              \t\t0.5095\t恰北北            \n",
      "\t-0.2584\t看              \t\t0.4271\t電話響            \n",
      "\t-0.2262\t阿              \t\t0.4048\t宵夜             \n",
      "\t-0.2016\t一樣             \t\t0.3874\t臉書             \n",
      "\t-0.1770\t男              \t\t0.3689\t覺得             \n",
      "\t-0.1750\t阿美             \t\t0.3604\t動物園            \n",
      "\n",
      "SVM, WordLevel TF-IDF: \n",
      "[1 3 3 2 3 2 3 3 1 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2311\t0.2311\t0.2311\tNone\n",
      "Macro\t0.3502\t0.2041\t0.1226\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0      1\n",
      "1     47\n",
      "2    883\n",
      "3    742\n",
      "4      1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1287\n",
      "1     387\n",
      "Name: result, dtype: int64\n",
      "0    0.768817\n",
      "1    0.231183\n",
      "Name: result, dtype: float64\n",
      "\t-0.5691\t看              \t\t1.2274\t覺得             \n",
      "\t-0.5066\t阿              \t\t1.1851\t番茄             \n",
      "\t-0.4837\t找              \t\t1.1486\t隨便             \n",
      "\t-0.3572\t一樣             \t\t1.0673\t層              \n",
      "\t-0.3560\t時候             \t\t1.0565\t小凝             \n",
      "\t-0.3276\t醫生             \t\t1.0326\t菜              \n",
      "\t-0.3182\t媽媽             \t\t0.9844\t電話響            \n",
      "\t-0.3131\t遠              \t\t0.9084\t湯圓             \n",
      "\t-0.3100\t最              \t\t0.9064\t小弟             \n",
      "\t-0.3072\t古人             \t\t0.9001\t大同             \n",
      "\n",
      "SVM, N-Gram Vectors: \n",
      "[1 3 3 2 3 3 3 3 1 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2252\t0.2252\t0.2252\tNone\n",
      "Macro\t0.1492\t0.2053\t0.12\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "1     47\n",
      "2    868\n",
      "3    758\n",
      "4      1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1297\n",
      "1     377\n",
      "Name: result, dtype: int64\n",
      "0    0.774791\n",
      "1    0.225209\n",
      "Name: result, dtype: float64\n",
      "\t-0.5214\t阿              \t\t1.1018\t覺得             \n",
      "\t-0.4697\t看              \t\t1.0285\t番茄             \n",
      "\t-0.3772\t時候             \t\t1.0136\t隨便             \n",
      "\t-0.3659\t找              \t\t0.9863\t小凝             \n",
      "\t-0.3362\t唱              \t\t0.9356\t衣服             \n",
      "\t-0.2927\t媽媽             \t\t0.9275\t層              \n",
      "\t-0.2895\t聽              \t\t0.8780\t我家             \n",
      "\t-0.2776\t男              \t\t0.8766\t樹              \n",
      "\t-0.2677\t遠              \t\t0.8737\t電話響            \n",
      "\t-0.2660\t一樣             \t\t0.8695\t大同             \n",
      "\n",
      "SVM, CharLevel Vectors: \n",
      "[1 2 3 2 2 3 3 3 1 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2275\t0.2275\t0.2275\tNone\n",
      "Macro\t0.3598\t0.1942\t0.1257\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0      1\n",
      "1     79\n",
      "2    852\n",
      "3    741\n",
      "4      1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1293\n",
      "1     381\n",
      "Name: result, dtype: int64\n",
      "0    0.772401\n",
      "1    0.227599\n",
      "Name: result, dtype: float64\n",
      "\t-0.3863\t阿              \t\t0.7962\t凝              \n",
      "\t-0.3547\t 阿             \t\t0.7103\t覺得             \n",
      "\t-0.3387\t有              \t\t0.6781\t女 不            \n",
      "\t-0.3386\t 看             \t\t0.6742\t頭 髮            \n",
      "\t-0.3355\t心              \t\t0.6585\t鍋              \n",
      "\t-0.3228\t看              \t\t0.6425\t安              \n",
      "\t-0.3141\t媽              \t\t0.6226\t茄              \n",
      "\t-0.2945\t 看             \t\t0.6132\t茄              \n",
      "\t-0.2871\t 有             \t\t0.6038\t覺得             \n",
      "\t-0.2858\t 抓             \t\t0.6013\t男 女            \n",
      "\n",
      "It takes 0.32 seconds for Linear SVM.\n"
     ]
    }
   ],
   "source": [
    "def Run_SVM():\n",
    "    \n",
    "    time_LinearSVM = time.time()\n",
    "\n",
    "# Use of class_weight='balanced' decrease accuracy, although PCWeb is unbalanced\n",
    "#accuracy = train_model(svm.SVC(class_weight='balanced'), xtrain_count, train_y, xtest_count)\n",
    "# LinearSVC() is much much better than SVC()\n",
    "    predict, clf = train_predict(svm.LinearSVC(), xtrain_count, train_y, xtest_count)\n",
    "    print(\"\\nSVM, Count Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(count_vect, clf, train_y, n=10)\n",
    "\n",
    "    predict, clf = train_predict(svm.LinearSVC(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "    print(\"\\nSVM, WordLevel TF-IDF: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect, clf, train_y, n=10)\n",
    "\n",
    "    predict, clf = train_predict(svm.LinearSVC(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "    print(\"\\nSVM, N-Gram Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram, clf, train_y, n=10)\n",
    "\n",
    "    predict, clf = train_predict(svm.LinearSVC(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "    print(\"\\nSVM, CharLevel Vectors: \")\n",
    "    show_Result(predict)\n",
    "    most_informative_feature_for_class(tfidf_vect_ngram_chars, clf, train_y, n=10)\n",
    "\n",
    "    print(\"\\nIt takes %4.2f seconds for Linear SVM.\"%(time.time()-time_LinearSVM))\n",
    "\n",
    "Run_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF, Count Vectors: \n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2598\t0.2598\t0.2598\tNone\n",
      "Macro\t0.1478\t0.1942\t0.1255\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0       1\n",
      "1      70\n",
      "2    1107\n",
      "3     493\n",
      "4       3\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1239\n",
      "1     435\n",
      "Name: result, dtype: int64\n",
      "0    0.740143\n",
      "1    0.259857\n",
      "Name: result, dtype: float64\n",
      "\n",
      "RF, WordLevel TF-IDF: \n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2514\t0.2514\t0.2514\tNone\n",
      "Macro\t0.1148\t0.1847\t0.1136\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0       1\n",
      "1      40\n",
      "2    1131\n",
      "3     501\n",
      "4       1\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1253\n",
      "1     421\n",
      "Name: result, dtype: int64\n",
      "0    0.748507\n",
      "1    0.251493\n",
      "Name: result, dtype: float64\n",
      "\n",
      "RF, N-Gram Vectors: \n",
      "[2 3 3 2 3 2 2 2 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2747\t0.2747\t0.2747\tNone\n",
      "Macro\t0.1505\t0.2082\t0.1281\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "1      41\n",
      "2    1140\n",
      "3     493\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1214\n",
      "1     460\n",
      "Name: result, dtype: int64\n",
      "0    0.725209\n",
      "1    0.274791\n",
      "Name: result, dtype: float64\n",
      "\n",
      "RF, CharLevel Vectors: \n",
      "[2 3 3 2 2 2 2 2 2 2]\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2299\t0.2299\t0.2299\tNone\n",
      "Macro\t0.2674\t0.1857\t0.1214\tNone\n",
      "0    316\n",
      "1    616\n",
      "2    571\n",
      "3    125\n",
      "4     46\n",
      "Name: HumorLevel, dtype: int64\n",
      "0      2\n",
      "1     56\n",
      "2    910\n",
      "3    706\n",
      "Name: FuninessLevel, dtype: int64\n",
      "0    1289\n",
      "1     385\n",
      "Name: result, dtype: int64\n",
      "0    0.770012\n",
      "1    0.229988\n",
      "Name: result, dtype: float64\n",
      "\n",
      "It takes 0.82 seconds for Random Forest.\n"
     ]
    }
   ],
   "source": [
    "def Run_RdnForest():\n",
    "    \n",
    "    time_RdnForest = time.time()\n",
    "\n",
    "# RF on Count Vectors\n",
    "    predict, clf = train_predict(ensemble.RandomForestClassifier(), xtrain_count, train_y, xtest_count)\n",
    "    print(\"\\nRF, Count Vectors: \")\n",
    "    show_Result(predict)\n",
    "    #most_informative_feature_for_class(count_vect, clf, train_y, n=10)\n",
    "    #'RandomForestClassifier' object has no attribute 'coef_'\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "    predict, clf = train_predict(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xtest_tfidf)\n",
    "    print(\"\\nRF, WordLevel TF-IDF: \")\n",
    "    show_Result(predict)\n",
    "\n",
    "    predict, clf = train_predict(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xtest_tfidf_ngram)\n",
    "    print(\"\\nRF, N-Gram Vectors: \")\n",
    "    show_Result(predict)\n",
    "\n",
    "    predict, clf = train_predict(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y, xtest_tfidf_ngram_chars)\n",
    "    print(\"\\nRF, CharLevel Vectors: \")\n",
    "    show_Result(predict)\n",
    "\n",
    "    print(\"\\nIt takes %4.2f seconds for Random Forest.\"%(time.time()-time_RdnForest))\n",
    "\n",
    "Run_RdnForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
