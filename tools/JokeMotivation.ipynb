{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Approaches to Multi-Label Classification\n",
    "\n",
    "This program is modified from https://github.com/nkartik94/Multi-Label-Text-Classification\n",
    "on 2019/11/18 by Yuen-Hsien Tseng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"mlabel_corpora/JokeMotivation.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 9)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "#data_raw = df.loc[np.random.choice(data_raw.index, size=2000)]\n",
    "print(df.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9)\n",
      "(1674, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ID=L1850 為分界，之前：吳玟萱，之後：黃亭筠，均為中文系同一屆\n",
    "train, test = train_test_split(df, train_size=1691, shuffle=False) \n",
    "# (tempararily) set global variables: train, test \n",
    "\n",
    "with open('mlabel_corpora/JokeMotivation_train.txt', 'w') as outF:\n",
    "    outF.write(train.to_csv(sep='\\t', index=False))\n",
    "\n",
    "with open('mlabel_corpora/JokeMotivation_test.txt', 'w') as outF:\n",
    "    outF.write(test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf[\\'Content\\'] = df[df.columns[1:3]].apply(\\n    lambda x: \\' 。 \\'.join(x.dropna().astype(str)),\\n    axis=1\\n)\\nprint(\"Number of rows in data =\",df.shape[0])\\nprint(\"Number of columns in data =\",df.shape[1])\\nprint(\"\\n\")\\nprintmd(\"**Sample data:**\")\\ndf.head()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not do this, because there are many duplicate titles\n",
    "# Merge Title into Content\n",
    "'''\n",
    "df['Content'] = df[df.columns[1:3]].apply(\n",
    "    lambda x: ' 。 '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Number of rows in data =\",df.shape[0])\n",
    "print(\"Number of columns in data =\",df.shape[1])\n",
    "print(\"\\n\")\n",
    "printmd(\"**Sample data:**\")\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  0\n",
      "Title               0\n",
      "Content             0\n",
      "Affinity            0\n",
      "Self_Improvement    0\n",
      "Attack              0\n",
      "Self_Depression     0\n",
      "Taboo               0\n",
      "Others              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = df.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s}= \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all jokes =  3365\n",
      "Number of clean jokes in all=  6\n",
      "Number of all jokes with labels = 3359\n",
      "\n",
      "Total number of all jokes =  1691\n",
      "Number of clean jokes in all=  5\n",
      "Number of all jokes with labels = 1686\n",
      "\n",
      "Total number of all jokes =  1674\n",
      "Number of clean jokes in all=  1\n",
      "Number of all jokes with labels = 1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_empty_label(df, 'all')\n",
    "print_empty_label(train, 'all')\n",
    "print_empty_label(test, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'Affinity', 'Self_Improvement', 'Attack', 'Self_Depression', 'Taboo', 'Others']\n",
      "['Affinity', 'Self_Improvement', 'Attack', 'Self_Depression', 'Taboo', 'Others']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[3:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of jokes in each category\n",
    "def print_category_count(df, categories):\n",
    "    counts = []\n",
    "    for category in categories:\n",
    "        counts.append((category, df[category].sum()))\n",
    "    df_stats = pd.DataFrame(counts, columns=['category', 'number of jokes'])\n",
    "    print(df_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category  number of jokes\n",
      "0          Affinity               92\n",
      "1  Self_Improvement               43\n",
      "2            Attack              409\n",
      "3   Self_Depression               64\n",
      "4             Taboo              584\n",
      "5            Others             2226\n",
      "\n",
      "           category  number of jokes\n",
      "0          Affinity               73\n",
      "1  Self_Improvement               27\n",
      "2            Attack              266\n",
      "3   Self_Depression               47\n",
      "4             Taboo              355\n",
      "5            Others              972\n",
      "\n",
      "           category  number of jokes\n",
      "0          Affinity               19\n",
      "1  Self_Improvement               16\n",
      "2            Attack              143\n",
      "3   Self_Depression               17\n",
      "4             Taboo              229\n",
      "5            Others             1254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_category_count(df, categories)\n",
    "print_category_count(train, categories)\n",
    "print_category_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df.iloc[:,3:].sum().values)\n",
    "\n",
    "    plt.title(\"Jokes in each category\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Joke Skill', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df.iloc[:,3:].sum().values\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_category_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Calculating number of jokes having multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_label(mlc_labels, multiLabel_counts):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax = sns.barplot(mlc_labels, multiLabel_counts.values)\n",
    "\n",
    "    plt.title(\"Jokes having multiple labels \")\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = multiLabel_counts.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_multiple_label(df):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    multiLabel_counts = rowSums.value_counts()\n",
    "    print(multiLabel_counts)\n",
    "    multiLabel_counts = multiLabel_counts.iloc[:]\n",
    "    #print(multiLabel_counts.index)\n",
    "    mlc_labels = ['L'+str(i) for i in multiLabel_counts.index]\n",
    "    print(mlc_labels)\n",
    "    \n",
    "    plot_multiple_label(mlc_labels, multiLabel_counts)\n",
    "    ##return(mlc_labels, multiLabel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3301\n",
      "2      57\n",
      "0       6\n",
      "3       1\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L0', 'L3']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_multiple_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. WordCloud representation of most used words in each category of jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import jieba\n",
    "import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, c in enumerate(categories):\\n    plt = MyWordCloud(plt, df, c, i+1)\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40,25))\n",
    "\n",
    "def MyWordCloud(plt, df, field, position):\n",
    "    #subset = df[df.Pun==1]\n",
    "    subset = df.loc[df[field] == 1] # https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "    #print(subset.head()); exit\n",
    "    text = str(subset.Content.values)\n",
    "    words_list = jieba.lcut(Stopwords.clean_text(text))\n",
    "    text = Stopwords.clean_words(words_list)\n",
    "    cloud = WordCloud(\n",
    "                          #stopwords=STOPWORDS,\n",
    "                          stopwords=Stopwords.STOP_WORDS,\n",
    "                          background_color='black',\n",
    "                          font_path='SNsanafonGyou.ttf', # OSError: unknown file format\n",
    "                          collocations=False,\n",
    "                          width=2500,\n",
    "                          height=1800\n",
    "                         ).generate(\" \".join(text))\n",
    "\n",
    "    plt.subplot(3, 3, position)\n",
    "    plt.axis('off')\n",
    "    plt.title(field, fontsize=40)\n",
    "    plt.imshow(cloud)\n",
    "    return plt\n",
    "\n",
    "'''\n",
    "for i, c in enumerate(categories):\n",
    "    plt = MyWordCloud(plt, df, c, i+1)\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in   all jokes: Max=2024, Min=10, Avg=134.07637444279345\n",
      "Number of characters in train jokes: Max=2024, Min=10, Avg=132.7906564163217\n",
      "Number of characters in  test jokes: Max=874, Min=12, Avg=135.3751493428913\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = df.Content.map(len)\n",
    "print(f'Number of characters in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(len)\n",
    "print(f'Number of characters in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(len)\n",
    "print(f'Number of characters in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set global variables: data\n",
    "data = df\n",
    "#data = df.loc[np.random.choice(df.index, size=3365)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stopwords # import my own module with STOP_WORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    Given a raw text string, return a clean text string.\n",
    "    Example: \n",
    "        input:  \"Years  passed. 多少   年过 去 了 。  \"\n",
    "        output: \"years passed.多少年过去了。\"\n",
    "    '''\n",
    "    text = str(text)\n",
    "    text = text.lower() # 'years  passed. 多少   年过 去 了 。'\n",
    "    # Next line will remove redundant white space for jeiba to cut\n",
    "    text = re.sub(r'\\s+([^a-zA-Z0-9.])', r'\\1', text) # years passed.多少年过去了。\n",
    "# see: https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_words(text, RmvStopWord=True, RmvMark=True):\n",
    "    words = jieba.lcut(text)\n",
    "#    print(\"After jieba.lcut():\", words)\n",
    "#    WL = [ w \n",
    "    WL = [ ps.stem(w)\n",
    "#    WL = [ wnl.lemmatize(w)\n",
    "        for w in words \n",
    "          if (not re.match(r'\\s', w)) # remove white spaces\n",
    "            and (RmvMark==False or not re.match(r'\\W', w)) # remove punctuations\n",
    "#            and (RmvMark==False or not re.match('^[a-z_]$', w)) # remove punctuations\n",
    "#            and (RmvMark==False or w not in PUNCTUATIONS)\n",
    "            and (RmvStopWord==False or w not in Stopwords.STOP_WORDS)\n",
    "            and (not re.match(r'^\\d+$', w)) # remove digit\n",
    "         ]\n",
    "    WL = \" \".join(WL)\n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/kg/jcdj05xn20144cv9kwywp26r0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Title                                            Content  Affinity  \\\n",
      "0  L0001  要求加薪  員工：老闆，您必須幫我加薪，已經有三家公司在找我了！     老闆：哪三家？     員工：...         0   \n",
      "1  L0002  查無此人  某市政府辦公大樓落成，門口缺副對聯。     副市長揮毫     上聯：說實話辦實事一身正氣...         0   \n",
      "2  L0003   遣散費  中午老闆視察自己的建築工地時，發現有個人在角落玩手機。     老闆：你月薪多少？     ...         0   \n",
      "3  L0004  職業習慣  一天，一位法官的女友看見兩個蚊子，便叫法官打死。     只見法官只把那個肚子飽飽的蚊子打死...         0   \n",
      "4  L0005  美女吵架  辦公室中兩位女同事吵起來了。     經理忍無可忍：「太不像話了！現在是什麼情況？你們把原因...         0   \n",
      "\n",
      "   Self_Improvement  Attack  Self_Depression  Taboo  Others  \n",
      "0                 0       0                1      0       0  \n",
      "1                 0       1                0      0       0  \n",
      "2                 0       0                1      0       0  \n",
      "3                 0       0                0      0       1  \n",
      "4                 0       1                0      0       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.624 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data['Content'] = data['Content'].str.lower()\n",
    "#data['Content'] = data['Content'].apply(cleanHtml)\n",
    "#data['Content'] = data['Content'].apply(cleanPunc)\n",
    "#data['Content'] = data['Content'].apply(keepAlpha)\n",
    "data['Content'] = data['Content'].apply(clean_text)\n",
    "data['Content'] = data['Content'].apply(clean_words)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['Content'] = data['Content'].apply(removeStopWords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Affinity</th>\n",
       "      <th>Self_Improvement</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Self_Depression</th>\n",
       "      <th>Taboo</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0001</td>\n",
       "      <td>要求加薪</td>\n",
       "      <td>員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0002</td>\n",
       "      <td>查無此人</td>\n",
       "      <td>某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0003</td>\n",
       "      <td>遣散費</td>\n",
       "      <td>中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0004</td>\n",
       "      <td>職業習慣</td>\n",
       "      <td>一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0005</td>\n",
       "      <td>美女吵架</td>\n",
       "      <td>辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Title                                            Content  Affinity  \\\n",
       "0  L0001  要求加薪  員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...         0   \n",
       "1  L0002  查無此人  某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...         0   \n",
       "2  L0003   遣散費  中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...         0   \n",
       "3  L0004  職業習慣  一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...         0   \n",
       "4  L0005  美女吵架  辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...         0   \n",
       "\n",
       "   Self_Improvement  Attack  Self_Depression  Taboo  Others  \n",
       "0                 0       0                1      0       0  \n",
       "1                 0       1                0      0       0  \n",
       "2                 0       0                1      0       0  \n",
       "3                 0       0                0      0       1  \n",
       "4                 0       1                0      0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['Content'] = data['Content'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9)\n",
      "(1674, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set global variables: train, test\n",
    "#train, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n",
    "train, test = train_test_split(data, random_state=42, train_size=1691, shuffle=False)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables: train_text, test_text\n",
    "train_text = train['Content']\n",
    "test_text = test['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in   all jokes: Max=491, Min=3, Avg=41.6222882615156\n",
      "Number of words in train jokes: Max=491, Min=3, Avg=40.33234772324069\n",
      "Number of words in  test jokes: Max=290, Min=4, Avg=42.92532855436081\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = data.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['ID', 'Title', 'Content'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['ID', 'Title', 'Content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_tfidf.shape:(1691, 9559), xtest_tfidf.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram.shape:(1691, 9559), xtest_tfidf_ngram.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram_chars.shape:(1691, 9559), xtest_tfidf_ngram_chars.shape: (1674, 9559)\n",
      "It takes 2.54 seconds to convert 3 TFxIDF vectors.\n"
     ]
    }
   ],
   "source": [
    "time_TfidfVector = time.time()\n",
    "\n",
    "def Create_TFxIDF(data_text, train_text, test_text):\n",
    "\n",
    "# word level tf-idf\n",
    "    #tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2, max_features=10000)\n",
    "    tfidf_vect.fit(data_text)\n",
    "    xtrain_tfidf = tfidf_vect.transform(train_text)\n",
    "    xtest_tfidf = tfidf_vect.transform(test_text)\n",
    "    print(f\"xtrain_tfidf.shape:{xtrain_tfidf.shape}, xtest_tfidf.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# word level ngram tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram.fit(data_text)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    print(f\"xtrain_tfidf_ngram.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# character level ngram tf-idf\n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram_chars.fit(data_text)\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "    xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) \n",
    "    print(f\"xtrain_tfidf_ngram_chars.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram_chars.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert 3 TFxIDF vectors.\"%(time.time()-time_TfidfVector))\n",
    "\n",
    "    return (xtrain_tfidf, xtest_tfidf, \n",
    "             xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    "             xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    "            tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars)\n",
    "\n",
    "(xtrain_tfidf, xtest_tfidf, \n",
    " xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    " xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    " tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars) = Create_TFxIDF(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9559) (1674, 9559)\n"
     ]
    }
   ],
   "source": [
    "# re-assign x_train and x_test to what we want\n",
    "x_train, x_test, vectorizer = xtrain_tfidf, xtest_tfidf, tfidf_vect\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram, xtest_tfidf_ngram, tfidf_vect_ngram\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars, tfidf_vect_ngram_chars\n",
    "print(x_train.shape, x_test.shape)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def tcfunc(x, n=4): # trancate a number to have n decimal digits\n",
    "    d = '0' * n\n",
    "    d = int('1' + d)\n",
    "# https://stackoverflow.com/questions/4541155/check-if-a-number-is-int-or-float\n",
    "    if isinstance(x, (int, float)): return int(x * d) / d\n",
    "    return x\n",
    "\n",
    "def print_cls_report(y_true, prediction):\n",
    "    print('Test accuracy is %1.4f'%(accuracy_score(y_true, prediction)))\n",
    "\n",
    "    print(classification_report(y_true, prediction))\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"\\tPrecision\\tRecall\\tF1\\tSupport\")\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='micro')))\n",
    "    print(\"Micro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='macro')))\n",
    "    print(\"Macro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    \n",
    "#    if True:\n",
    "    if False:\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        try: \n",
    "            print(classification_report(y_true, prediction, digits=4))\n",
    "        except ValueError:\n",
    "            print('May be some category has no predicted samples')\n",
    "        show_confusion_matrix(prediction)\n",
    "\n",
    "\n",
    "    print(f'y_true.shape={y_true.shape}, prediction.shape={prediction.shape}')\n",
    "    #print(y_true.head())\n",
    "    #print(prediction[0:6])\n",
    "\n",
    "    # https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python\n",
    "    pred = prediction\n",
    "    if not isinstance(pred, np.ndarray): pred = prediction.toarray()\n",
    "    print(type(y_true), type(prediction), type(pred))\n",
    "    try:\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "        print('macro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='macro'))) # default average=’macro’\n",
    "        print('micro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='micro')))\n",
    "    except:\n",
    "        print(\"roc_auc_score error!!!\")\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, pred)\n",
    "        print(f'fpr={fpr}\\ntpr={tpr}\\nthresholds={thresholds}')\n",
    "    except:\n",
    "        print('roc_curve error!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Processing Affinity jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1655\n",
      "           1       0.40      0.11      0.17        19\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1674\n",
      "   macro avg       0.69      0.55      0.58      1674\n",
      "weighted avg       0.98      0.99      0.98      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.988\t0.988\t0.988\tNone\n",
      "Macro\t0.6949\t0.5517\t0.5803\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5517\n",
      "micro roc_auc_score is 0.5517\n",
      "fpr=[0.         0.00181269 1.        ]\n",
      "tpr=[0.         0.10526316 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Self_Improvement jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1658\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1674\n",
      "   macro avg       0.50      0.50      0.50      1674\n",
      "weighted avg       0.98      0.99      0.99      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9904\t0.9904\t0.9904\tNone\n",
      "Macro\t0.4952\t0.5\t0.4975\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Attack jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      1531\n",
      "           1       0.00      0.00      0.00       143\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1674\n",
      "   macro avg       0.46      0.50      0.48      1674\n",
      "weighted avg       0.84      0.91      0.87      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9145\t0.9145\t0.9145\tNone\n",
      "Macro\t0.4572\t0.5\t0.4776\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Self_Depression jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1657\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1674\n",
      "   macro avg       0.49      0.50      0.50      1674\n",
      "weighted avg       0.98      0.99      0.98      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9898\t0.9898\t0.9898\tNone\n",
      "Macro\t0.4949\t0.5\t0.4974\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Taboo jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      1445\n",
      "           1       1.00      0.00      0.01       229\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1674\n",
      "   macro avg       0.93      0.50      0.47      1674\n",
      "weighted avg       0.88      0.86      0.80      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8637\t0.8637\t0.8637\tNone\n",
      "Macro\t0.9318\t0.5021\t0.4677\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5022\n",
      "micro roc_auc_score is 0.5022\n",
      "fpr=[0. 0. 1.]\n",
      "tpr=[0.         0.00436681 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Others jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.6493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.33       420\n",
      "           1       0.77      0.75      0.76      1254\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      1674\n",
      "   macro avg       0.55      0.55      0.55      1674\n",
      "weighted avg       0.66      0.65      0.65      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.6493\t0.6493\t0.6493\tNone\n",
      "Macro\t0.5469\t0.5498\t0.5478\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5498\n",
      "micro roc_auc_score is 0.5498\n",
      "fpr=[0.   0.65 1.  ]\n",
      "tpr=[0.         0.74960128 1.        ]\n",
      "thresholds=[2 1 0]\n",
      "CPU times: user 112 ms, sys: 80.8 ms, total: 192 ms\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "#for category in categories:\n",
    "for category in categories:\n",
    "    printmd('**Processing {} jokes...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    \n",
    "    print_cls_report(test[category], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Multiple Binary Classifications - (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use binary relevance, run \"pip install scikit-multilearn\" in advance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Next line refers to: http://scikit.ml/tutorial.html\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with GaussianNB()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.3829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.12      0.13      0.12       143\n",
      "           3       0.20      0.06      0.09        17\n",
      "           4       0.18      0.22      0.20       229\n",
      "           5       0.76      0.49      0.60      1254\n",
      "\n",
      "   micro avg       0.54      0.41      0.47      1678\n",
      "   macro avg       0.21      0.15      0.17      1678\n",
      "weighted avg       0.61      0.41      0.48      1678\n",
      " samples avg       0.40      0.41      0.40      1678\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.5449\t0.4082\t0.4667\tNone\n",
      "Macro\t0.2094\t0.15\t0.168\tNone\n",
      "y_true.shape=(1674, 6), prediction.shape=(1674, 6)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5154\n",
      "micro roc_auc_score is 0.6699\n",
      "roc_curve error!!!\n",
      "CPU times: user 9.29 s, sys: 684 ms, total: 9.97 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "#   with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with GaussianNB()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with LinearSVC()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.4188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.11      0.13        19\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.14      0.23      0.18       143\n",
      "           3       0.00      0.00      0.00        17\n",
      "           4       0.23      0.29      0.25       229\n",
      "           5       0.79      0.53      0.63      1254\n",
      "\n",
      "   micro avg       0.56      0.45      0.50      1678\n",
      "   macro avg       0.22      0.19      0.20      1678\n",
      "weighted avg       0.64      0.45      0.52      1678\n",
      " samples avg       0.44      0.45      0.44      1678\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.5554\t0.4535\t0.4993\tNone\n",
      "Macro\t0.2239\t0.1917\t0.1994\tNone\n",
      "y_true.shape=(1674, 6), prediction.shape=(1674, 6)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5369\n",
      "micro roc_auc_score is 0.6904\n",
      "roc_curve error!!!\n",
      "CPU times: user 1.18 s, sys: 166 ms, total: 1.34 s\n",
      "Wall time: 591 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Next line refers to: http://scikit.ml/tutorial.html and \n",
    "#   http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "#classifier = BinaryRelevance(classifier=SVC(), require_dense=[False, True]) # 0.5 very bad!\n",
    "# https://scikit-learn.org/stable/modules/svm.html#unbalanced-problems\n",
    "classifier = BinaryRelevance(classifier=LinearSVC(class_weight='balanced')) # 0.5369\n",
    "#classifier = BinaryRelevance(classifier=LinearSVC()) # Test roc_auc_score is 0.5246\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with LinearSVC()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Classifier Chains with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.5675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.11      0.13        19\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.14      0.23      0.17       143\n",
      "           3       0.00      0.00      0.00        17\n",
      "           4       0.20      0.28      0.24       229\n",
      "           5       0.77      0.69      0.73      1254\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1678\n",
      "   macro avg       0.22      0.22      0.21      1678\n",
      "weighted avg       0.62      0.57      0.59      1678\n",
      " samples avg       0.57      0.57      0.57      1678\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.5683\t0.5727\t0.5704\tNone\n",
      "Macro\t0.2155\t0.2177\t0.2115\tNone\n",
      "y_true.shape=(1674, 6), prediction.shape=(1674, 6)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5312\n",
      "micro roc_auc_score is 0.7427\n",
      "roc_curve error!!!\n",
      "CPU times: user 2.29 s, sys: 701 ms, total: 2.99 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "#classifier = ClassifierChain(LogisticRegression()) # Test roc_auc_score is \n",
    "classifier = ClassifierChain(LinearSVC(class_weight='balanced')) #  0.5312\n",
    "\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Classifier Chains with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Label Powerset with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.5227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.16      0.14        19\n",
      "           1       0.10      0.06      0.08        16\n",
      "           2       0.15      0.31      0.20       143\n",
      "           3       0.00      0.00      0.00        17\n",
      "           4       0.19      0.30      0.23       229\n",
      "           5       0.78      0.61      0.69      1254\n",
      "\n",
      "   micro avg       0.52      0.53      0.53      1678\n",
      "   macro avg       0.23      0.24      0.22      1678\n",
      "weighted avg       0.62      0.53      0.57      1678\n",
      " samples avg       0.53      0.53      0.53      1678\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.5226\t0.5286\t0.5256\tNone\n",
      "Macro\t0.225\t0.2399\t0.2232\tNone\n",
      "y_true.shape=(1674, 6), prediction.shape=(1674, 6)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5440\n",
      "micro roc_auc_score is 0.7159\n",
      "roc_curve error!!!\n",
      "CPU times: user 893 ms, sys: 56.5 ms, total: 949 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "#classifier = LabelPowerset(LogisticRegression()) # Test roc_auc_score is ?\n",
    "classifier = LabelPowerset(LinearSVC(class_weight='balanced')) # 0.5440\n",
    "# Test roc_auc_score is ? if xtrain_tfidf_ngram, xtest_tfidf_ngram are used.\n",
    "# Test roc_auc_score is ? if xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars are used\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Label Powerset with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/Motivation_True.txt', 'w') as outF:\n",
    "    outF.write(y_test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "with open('out/Motivation_Pred.txt', 'w') as outF:\n",
    "    outF.write(pd.DataFrame(predictions.toarray(), columns=list(y_test.columns)).to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Adapted Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MLkNN**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.3937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.15        19\n",
      "           1       0.00      0.00      0.00        16\n",
      "           2       0.17      0.08      0.11       143\n",
      "           3       0.00      0.00      0.00        17\n",
      "           4       0.16      0.10      0.12       229\n",
      "           5       0.80      0.50      0.61      1254\n",
      "\n",
      "   micro avg       0.66      0.39      0.49      1678\n",
      "   macro avg       0.24      0.13      0.17      1678\n",
      "weighted avg       0.64      0.39      0.49      1678\n",
      " samples avg       0.39      0.39      0.39      1678\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.6636\t0.3939\t0.4943\tNone\n",
      "Macro\t0.2361\t0.1306\t0.1667\tNone\n",
      "y_true.shape=(1674, 6), prediction.shape=(1674, 6)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5240\n",
      "micro roc_auc_score is 0.6769\n",
      "roc_curve error!!!\n",
      "CPU times: user 1min 9s, sys: 231 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_new = MLkNN(k=10)\n",
    "\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "\n",
    "printmd('**MLkNN**')\n",
    "print_cls_report(y_test, predictions_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
