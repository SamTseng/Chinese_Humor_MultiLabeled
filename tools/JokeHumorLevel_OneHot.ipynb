{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Approaches to Multi-Label Classification\n",
    "\n",
    "This program is modified from https://github.com/nkartik94/Multi-Label-Text-Classification\n",
    "on 2019/11/18 by Yuen-Hsien Tseng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path  = \"../mlabel_corpora/JokeHumorLevel_OneHot.txt\"\n",
    "train_path = \"../mlabel_corpora/JokeHumorLevel_train_OneHot.txt\"\n",
    "test_path  = \"../mlabel_corpora/JokeHumorLevel_test_OneHot.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 9) (1691, 9) (1674, 9)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "train = pd.read_csv(train_path, delimiter=\"\\t\")\n",
    "test = pd.read_csv(test_path, delimiter=\"\\t\")\n",
    "print(df.shape, train.shape, test.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID            0\n",
      "Title         0\n",
      "Content       0\n",
      "HumorLevel    0\n",
      "1             0\n",
      "2             0\n",
      "3             0\n",
      "4             0\n",
      "5             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = df.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s}= \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all jokes =  3365\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 3365\n",
      "\n",
      "Total number of all jokes =  1691\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1691\n",
      "\n",
      "Total number of all jokes =  1674\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_empty_label(df, 'all')\n",
    "print_empty_label(train, 'all')\n",
    "print_empty_label(test, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'HumorLevel', '1', '2', '3', '4', '5']\n",
      "['1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[4:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of jokes in each category\n",
    "def print_category_count(df, categories):\n",
    "    counts = []\n",
    "    for category in categories:\n",
    "        counts.append((category, df[category].sum()))\n",
    "    df_stats = pd.DataFrame(counts, columns=['category', 'number of jokes'])\n",
    "    print(df_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  number of jokes\n",
      "0        1              363\n",
      "1        2              867\n",
      "2        3             1313\n",
      "3        4              729\n",
      "4        5               93\n",
      "\n",
      "  category  number of jokes\n",
      "0        1               47\n",
      "1        2              251\n",
      "2        3              742\n",
      "3        4              604\n",
      "4        5               47\n",
      "\n",
      "  category  number of jokes\n",
      "0        1              316\n",
      "1        2              616\n",
      "2        3              571\n",
      "3        4              125\n",
      "4        5               46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_category_count(df, categories)\n",
    "print_category_count(train, categories)\n",
    "print_category_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df.iloc[:,3:].sum().values)\n",
    "\n",
    "    plt.title(\"Jokes in each category\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Joke Skill', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df.iloc[:,3:].sum().values\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_category_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Calculating number of jokes having multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_label(mlc_labels, multiLabel_counts):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax = sns.barplot(mlc_labels, multiLabel_counts.values)\n",
    "\n",
    "    plt.title(\"Jokes having multiple labels \")\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = multiLabel_counts.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_multiple_label(df):\n",
    "    rowSums = df.iloc[:,4:].sum(axis=1)\n",
    "    multiLabel_counts = rowSums.value_counts()\n",
    "    print(multiLabel_counts)\n",
    "    multiLabel_counts = multiLabel_counts.iloc[:]\n",
    "    #print(multiLabel_counts.index)\n",
    "    mlc_labels = ['L'+str(i) for i in multiLabel_counts.index]\n",
    "    print(mlc_labels)\n",
    "    \n",
    "    plot_multiple_label(mlc_labels, multiLabel_counts)\n",
    "    ##return(mlc_labels, multiLabel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3365\n",
      "dtype: int64\n",
      "['L1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samm1/anaconda3/envs/WoS/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_multiple_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. WordCloud representation of most used words in each category of jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import jieba\n",
    "import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, c in enumerate(categories):\\n    plt = MyWordCloud(plt, df, c, i+1)\\n\\n#plt.show()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40,25))\n",
    "\n",
    "def MyWordCloud(plt, df, field, position):\n",
    "    #subset = df[df.Pun==1]\n",
    "    subset = df.loc[df[field] == 1] # https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "    #print(subset.head()); exit\n",
    "    text = str(subset.Content.values)\n",
    "    words_list = jieba.lcut(Stopwords.clean_text(text))\n",
    "    text = Stopwords.clean_words(words_list)\n",
    "    cloud = WordCloud(\n",
    "                          #stopwords=STOPWORDS,\n",
    "                          stopwords=Stopwords.STOP_WORDS,\n",
    "                          background_color='black',\n",
    "                          font_path='SNsanafonGyou.ttf', # OSError: unknown file format\n",
    "                          collocations=False,\n",
    "                          width=2500,\n",
    "                          height=1800\n",
    "                         ).generate(\" \".join(text))\n",
    "\n",
    "    plt.subplot(3, 3, position)\n",
    "    plt.axis('off')\n",
    "    plt.title(field, fontsize=40)\n",
    "    plt.imshow(cloud)\n",
    "    return plt\n",
    "\n",
    "'''\n",
    "for i, c in enumerate(categories):\n",
    "    plt = MyWordCloud(plt, df, c, i+1)\n",
    "\n",
    "#plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in   all jokes: Max=2024, Min=10, Avg=134.07637444279345\n",
      "Number of characters in train jokes: Max=2024, Min=10, Avg=132.7906564163217\n",
      "Number of characters in  test jokes: Max=874, Min=12, Avg=135.3751493428913\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = df.Content.map(len)\n",
    "print(f'Number of characters in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(len)\n",
    "print(f'Number of characters in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(len)\n",
    "print(f'Number of characters in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set global variables: data\n",
    "data = df\n",
    "#data = df.loc[np.random.choice(df.index, size=3365)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stopwords # import my own module with STOP_WORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    Given a raw text string, return a clean text string.\n",
    "    Example: \n",
    "        input:  \"Years  passed.         \"\n",
    "        output: \"years passed.\"\n",
    "    '''\n",
    "    text = str(text)\n",
    "    text = text.lower() # 'years  passed.       '\n",
    "    # Next line will remove redundant white space for jeiba to cut\n",
    "    text = re.sub(r'\\s+([^a-zA-Z0-9.])', r'\\1', text) # years passed.\n",
    "# see: https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_words(text, RmvStopWord=True, RmvMark=True):\n",
    "    words = jieba.lcut(text)\n",
    "#    print(\"After jieba.lcut():\", words)\n",
    "#    WL = [ w \n",
    "    WL = [ ps.stem(w)\n",
    "#    WL = [ wnl.lemmatize(w)\n",
    "        for w in words \n",
    "          if (not re.match(r'\\s', w)) # remove white spaces\n",
    "            and (RmvMark==False or not re.match(r'\\W', w)) # remove punctuations\n",
    "#            and (RmvMark==False or not re.match('^[a-z_]$', w)) # remove punctuations\n",
    "#            and (RmvMark==False or w not in PUNCTUATIONS)\n",
    "            and (RmvStopWord==False or w not in Stopwords.STOP_WORDS)\n",
    "            and (not re.match(r'^\\d+$', w)) # remove digit\n",
    "         ]\n",
    "    WL = \" \".join(WL)\n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jh/lksld56x4_10wxpq687st0x80000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Title                                            Content  HumorLevel  \\\n",
      "0  L0001              ...           4   \n",
      "1  L0002              ...           3   \n",
      "2  L0003               ...           4   \n",
      "3  L0004         ...           2   \n",
      "4  L0005         ...           4   \n",
      "\n",
      "   1  2  3  4  5  \n",
      "0  0  0  0  1  0  \n",
      "1  0  0  1  0  0  \n",
      "2  0  0  0  1  0  \n",
      "3  0  1  0  0  0  \n",
      "4  0  0  0  1  0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.463 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data['Content'] = data['Content'].str.lower()\n",
    "#data['Content'] = data['Content'].apply(cleanHtml)\n",
    "#data['Content'] = data['Content'].apply(cleanPunc)\n",
    "#data['Content'] = data['Content'].apply(keepAlpha)\n",
    "data['Content'] = data['Content'].apply(clean_text)\n",
    "data['Content'] = data['Content'].apply(clean_words)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['Content'] = data['Content'].apply(removeStopWords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>HumorLevel</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0001</td>\n",
       "      <td></td>\n",
       "      <td>                 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0002</td>\n",
       "      <td></td>\n",
       "      <td>                ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0003</td>\n",
       "      <td></td>\n",
       "      <td>                  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0004</td>\n",
       "      <td></td>\n",
       "      <td>                ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0005</td>\n",
       "      <td></td>\n",
       "      <td>               ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Title                                            Content  HumorLevel  \\\n",
       "0  L0001                     ...           4   \n",
       "1  L0002                    ...           3   \n",
       "2  L0003                       ...           4   \n",
       "3  L0004                    ...           2   \n",
       "4  L0005                   ...           4   \n",
       "\n",
       "   1  2  3  4  5  \n",
       "0  0  0  0  1  0  \n",
       "1  0  0  1  0  0  \n",
       "2  0  0  0  1  0  \n",
       "3  0  1  0  0  0  \n",
       "4  0  0  0  1  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['Content'] = data['Content'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9)\n",
      "(1674, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set global variables: train, test\n",
    "#train, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n",
    "train, test = train_test_split(data, random_state=42, train_size=1691, shuffle=False)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables: train_text, test_text\n",
    "train_text = train['Content']\n",
    "test_text = test['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in   all jokes: Max=491, Min=3, Avg=41.621991084695395\n",
      "Number of words in train jokes: Max=491, Min=3, Avg=40.33234772324069\n",
      "Number of words in  test jokes: Max=290, Min=4, Avg=42.924731182795696\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = data.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['ID', 'Title', 'Content', 'HumorLevel'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['ID', 'Title', 'Content', 'HumorLevel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_tfidf.shape:(1691, 9559), xtest_tfidf.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram.shape:(1691, 9559), xtest_tfidf_ngram.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram_chars.shape:(1691, 9559), xtest_tfidf_ngram_chars.shape: (1674, 9559)\n",
      "It takes 1.99 seconds to convert 3 TFxIDF vectors.\n"
     ]
    }
   ],
   "source": [
    "time_TfidfVector = time.time()\n",
    "\n",
    "def Create_TFxIDF(data_text, train_text, test_text):\n",
    "\n",
    "# word level tf-idf\n",
    "    #tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2, max_features=10000)\n",
    "    tfidf_vect.fit(data_text)\n",
    "    xtrain_tfidf = tfidf_vect.transform(train_text)\n",
    "    xtest_tfidf = tfidf_vect.transform(test_text)\n",
    "    print(f\"xtrain_tfidf.shape:{xtrain_tfidf.shape}, xtest_tfidf.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# word level ngram tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram.fit(data_text)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    print(f\"xtrain_tfidf_ngram.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# character level ngram tf-idf\n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram_chars.fit(data_text)\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "    xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) \n",
    "    print(f\"xtrain_tfidf_ngram_chars.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram_chars.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert 3 TFxIDF vectors.\"%(time.time()-time_TfidfVector))\n",
    "\n",
    "    return (xtrain_tfidf, xtest_tfidf, \n",
    "             xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    "             xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    "            tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars)\n",
    "\n",
    "(xtrain_tfidf, xtest_tfidf, \n",
    " xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    " xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    " tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars) = Create_TFxIDF(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9559) (1674, 9559)\n"
     ]
    }
   ],
   "source": [
    "# re-assign x_train and x_test to what we want\n",
    "x_train, x_test, vectorizer = xtrain_tfidf, xtest_tfidf, tfidf_vect\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram, xtest_tfidf_ngram, tfidf_vect_ngram\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars, tfidf_vect_ngram_chars\n",
    "print(x_train.shape, x_test.shape)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def tcfunc(x, n=4): # trancate a number to have n decimal digits\n",
    "    d = '0' * n\n",
    "    d = int('1' + d)\n",
    "# https://stackoverflow.com/questions/4541155/check-if-a-number-is-int-or-float\n",
    "    if isinstance(x, (int, float)): return int(x * d) / d\n",
    "    return x\n",
    "\n",
    "def print_cls_report(y_true, prediction):\n",
    "    print('Test accuracy is %1.4f'%(accuracy_score(y_true, prediction)))\n",
    "\n",
    "    print(classification_report(y_true, prediction))\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"\\tPrecision\\tRecall\\tF1\\tSupport\")\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='micro')))\n",
    "    print(\"Micro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='macro')))\n",
    "    print(\"Macro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    \n",
    "#    if True:\n",
    "    if False:\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        try: \n",
    "            print(classification_report(y_true, prediction, digits=4))\n",
    "        except ValueError:\n",
    "            print('May be some category has no predicted samples')\n",
    "        show_confusion_matrix(prediction)\n",
    "\n",
    "\n",
    "    print(f'y_true.shape={y_true.shape}, prediction.shape={prediction.shape}')\n",
    "    #print(y_true.head())\n",
    "    #print(prediction[0:6])\n",
    "\n",
    "    # https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python\n",
    "    pred = prediction\n",
    "    if not isinstance(pred, np.ndarray): pred = prediction.toarray()\n",
    "    print(type(y_true), type(prediction), type(pred))\n",
    "    try:\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "        print('macro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='macro'))) # default average=macro\n",
    "        print('micro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='micro')))\n",
    "    except:\n",
    "        print(\"roc_auc_score error!!!\")\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, pred)\n",
    "        print(f'fpr={fpr}\\ntpr={tpr}\\nthresholds={thresholds}')\n",
    "    except:\n",
    "        print('roc_curve error!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Processing 1 jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90      1358\n",
      "           1       0.00      0.00      0.00       316\n",
      "\n",
      "    accuracy                           0.81      1674\n",
      "   macro avg       0.41      0.50      0.45      1674\n",
      "weighted avg       0.66      0.81      0.73      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8112\t0.8112\t0.8112\tNone\n",
      "Macro\t0.4056\t0.5\t0.4478\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing 2 jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.6320\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77      1058\n",
      "           1       0.00      0.00      0.00       616\n",
      "\n",
      "    accuracy                           0.63      1674\n",
      "   macro avg       0.32      0.50      0.39      1674\n",
      "weighted avg       0.40      0.63      0.49      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.632\t0.632\t0.632\tNone\n",
      "Macro\t0.316\t0.5\t0.3872\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing 3 jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.6350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76      1103\n",
      "           1       0.40      0.15      0.22       571\n",
      "\n",
      "    accuracy                           0.64      1674\n",
      "   macro avg       0.54      0.52      0.49      1674\n",
      "weighted avg       0.58      0.64      0.58      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.635\t0.635\t0.635\tNone\n",
      "Macro\t0.5363\t0.5177\t0.4898\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5178\n",
      "micro roc_auc_score is 0.5178\n",
      "fpr=[0.         0.11332729 1.        ]\n",
      "tpr=[0.         0.14886165 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing 4 jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1549\n",
      "           1       0.12      0.08      0.10       125\n",
      "\n",
      "    accuracy                           0.89      1674\n",
      "   macro avg       0.53      0.52      0.52      1674\n",
      "weighted avg       0.87      0.89      0.88      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8888\t0.8888\t0.8888\tNone\n",
      "Macro\t0.5256\t0.517\t0.5189\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5171\n",
      "micro roc_auc_score is 0.5171\n",
      "fpr=[0.         0.04583602 1.        ]\n",
      "tpr=[0.   0.08 1.  ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing 5 jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1628\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.97      1674\n",
      "   macro avg       0.49      0.50      0.49      1674\n",
      "weighted avg       0.95      0.97      0.96      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9725\t0.9725\t0.9725\tNone\n",
      "Macro\t0.4862\t0.5\t0.493\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n",
      "CPU times: user 78.9 ms, sys: 153 ms, total: 232 ms\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "#for category in categories:\n",
    "for category in categories:\n",
    "    printmd('**Processing {} jokes...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print_cls_report(test[category], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Multiple Binary Classifications - (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use binary relevance, run \"pip install scikit-multilearn\" in advance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Next line refers to: http://scikit.ml/tutorial.html\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with GaussianNB()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.00      0.01       316\n",
      "           1       0.39      0.05      0.08       616\n",
      "           2       0.38      0.28      0.32       571\n",
      "           3       0.09      0.50      0.15       125\n",
      "           4       0.12      0.02      0.04        46\n",
      "\n",
      "   micro avg       0.20      0.15      0.17      1674\n",
      "   macro avg       0.25      0.17      0.12      1674\n",
      "weighted avg       0.33      0.15      0.15      1674\n",
      " samples avg       0.14      0.15      0.14      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2039\t0.1529\t0.1748\tNone\n",
      "Macro\t0.2452\t0.1719\t0.1194\tNone\n",
      "y_true.shape=(1674, 5), prediction.shape=(1674, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5132\n",
      "micro roc_auc_score is 0.5019\n",
      "roc_curve error!!!\n",
      "CPU times: user 683 ms, sys: 174 ms, total: 856 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "#   with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with GaussianNB()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with LinearSVC()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       316\n",
      "           1       0.30      0.04      0.07       616\n",
      "           2       0.36      0.42      0.39       571\n",
      "           3       0.07      0.34      0.11       125\n",
      "           4       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.22      0.18      0.20      1674\n",
      "   macro avg       0.14      0.16      0.11      1674\n",
      "weighted avg       0.24      0.18      0.16      1674\n",
      " samples avg       0.17      0.18      0.17      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2162\t0.1816\t0.1974\tNone\n",
      "Macro\t0.1446\t0.1596\t0.1123\tNone\n",
      "y_true.shape=(1674, 5), prediction.shape=(1674, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.4960\n",
      "micro roc_auc_score is 0.5085\n",
      "roc_curve error!!!\n",
      "CPU times: user 514 ms, sys: 204 ms, total: 719 ms\n",
      "Wall time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Next line refers to: http://scikit.ml/tutorial.html and \n",
    "#   http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "#classifier = BinaryRelevance(classifier=SVC(), require_dense=[False, True]) # 0.5 very bad!\n",
    "# https://scikit-learn.org/stable/modules/svm.html#unbalanced-problems\n",
    "classifier = BinaryRelevance(classifier=LinearSVC(class_weight='balanced')) # 0.5314\n",
    "#classifier = BinaryRelevance(classifier=LinearSVC()) # Test roc_auc_score is 0.5234\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with LinearSVC()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Classifier Chains with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.2336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       316\n",
      "           1       0.31      0.04      0.07       616\n",
      "           2       0.35      0.55      0.42       571\n",
      "           3       0.08      0.43      0.13       125\n",
      "           4       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.23      0.23      0.23      1674\n",
      "   macro avg       0.15      0.20      0.13      1674\n",
      "weighted avg       0.24      0.23      0.18      1674\n",
      " samples avg       0.23      0.23      0.23      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2335\t0.2335\t0.2335\tNone\n",
      "Macro\t0.1466\t0.2037\t0.1256\tNone\n",
      "y_true.shape=(1674, 5), prediction.shape=(1674, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5020\n",
      "micro roc_auc_score is 0.5210\n",
      "roc_curve error!!!\n",
      "CPU times: user 978 ms, sys: 1.28 s, total: 2.25 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "#classifier = ClassifierChain(LogisticRegression()) # Test roc_auc_score is 0.5159\n",
    "classifier = ClassifierChain(LinearSVC(class_weight='balanced')) #  0.5327\n",
    "\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Classifier Chains with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Label Powerset with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.2174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.01      0.01       316\n",
      "           1       0.33      0.06      0.10       616\n",
      "           2       0.35      0.48      0.41       571\n",
      "           3       0.07      0.43      0.12       125\n",
      "           4       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.22      0.22      0.22      1674\n",
      "   macro avg       0.21      0.19      0.13      1674\n",
      "weighted avg       0.30      0.22      0.19      1674\n",
      " samples avg       0.22      0.22      0.22      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2174\t0.2174\t0.2174\tNone\n",
      "Macro\t0.2084\t0.1946\t0.1275\tNone\n",
      "y_true.shape=(1674, 5), prediction.shape=(1674, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.4976\n",
      "micro roc_auc_score is 0.5109\n",
      "roc_curve error!!!\n",
      "CPU times: user 283 ms, sys: 478 ms, total: 761 ms\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "#classifier = LabelPowerset(LogisticRegression()) # Test roc_auc_score is 0.5059\n",
    "classifier = LabelPowerset(LinearSVC(class_weight='balanced')) # 0.5541\n",
    "# Test roc_auc_score is 0.5312 if xtrain_tfidf_ngram, xtest_tfidf_ngram are used.\n",
    "# Test roc_auc_score is 0.5474 if xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars are used\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Label Powerset with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('out/HumorLevel_True.txt', 'w') as outF:\n",
    "#    outF.write(y_test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "# with open('out/HumorLevel_Pred.txt', 'w') as outF:\n",
    "#    outF.write(pd.DataFrame(predictions.toarray(), columns=list(y_test.columns)).to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Adapted Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MLkNN**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       316\n",
      "           1       0.33      0.00      0.01       616\n",
      "           2       0.34      0.41      0.37       571\n",
      "           3       0.08      0.37      0.13       125\n",
      "           4       0.00      0.00      0.00        46\n",
      "\n",
      "   micro avg       0.22      0.17      0.19      1674\n",
      "   macro avg       0.15      0.16      0.10      1674\n",
      "weighted avg       0.25      0.17      0.14      1674\n",
      " samples avg       0.16      0.17      0.17      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2193\t0.169\t0.1909\tNone\n",
      "Macro\t0.1507\t0.1565\t0.1015\tNone\n",
      "y_true.shape=(1674, 5), prediction.shape=(1674, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5014\n",
      "micro roc_auc_score is 0.5093\n",
      "roc_curve error!!!\n",
      "CPU times: user 7.65 s, sys: 2.61 s, total: 10.3 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_new = MLkNN(k=10)\n",
    "\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "\n",
    "printmd('**MLkNN**')\n",
    "print_cls_report(y_test, predictions_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
