{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Approaches to Multi-Label Classification\n",
    "\n",
    "This program is modified from https://github.com/nkartik94/Multi-Label-Text-Classification\n",
    "on 2019/11/18 by Yuen-Hsien Tseng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"mlabel_corpora/JokeSkill.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 11)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "#data_raw = df.loc[np.random.choice(data_raw.index, size=2000)]\n",
    "print(df.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 11)\n",
      "(1674, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ID=L1850 為分界，之前：吳玟萱，之後：黃亭筠，均為中文系同一屆\n",
    "train, test = train_test_split(df, train_size=1691, shuffle=False) \n",
    "# (tempararily) set global variables: train, test \n",
    "\n",
    "with open('mlabel_corpora/JokeSkill_train.txt', 'w') as outF:\n",
    "    outF.write(train.to_csv(sep='\\t', index=False))\n",
    "\n",
    "with open('mlabel_corpora/JokeSkill_test.txt', 'w') as outF:\n",
    "    outF.write(test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf[\\'Content\\'] = df[df.columns[1:3]].apply(\\n    lambda x: \\' 。 \\'.join(x.dropna().astype(str)),\\n    axis=1\\n)\\nprint(\"Number of rows in data =\",df.shape[0])\\nprint(\"Number of columns in data =\",df.shape[1])\\nprint(\"\\n\")\\nprintmd(\"**Sample data:**\")\\ndf.head()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not do this, because there are many duplicate titles\n",
    "# Merge Title into Content\n",
    "'''\n",
    "df['Content'] = df[df.columns[1:3]].apply(\n",
    "    lambda x: ' 。 '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Number of rows in data =\",df.shape[0])\n",
    "print(\"Number of columns in data =\",df.shape[1])\n",
    "print(\"\\n\")\n",
    "printmd(\"**Sample data:**\")\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  0\n",
      "Title               0\n",
      "Content             0\n",
      "Pun                 0\n",
      "Exaggeration        0\n",
      "Anthropomorphism    0\n",
      "Bridge_Inference    0\n",
      "Illogical           0\n",
      "Irony               0\n",
      "Imitation           0\n",
      "Others              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = df.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s}= \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all jokes =  3365\n",
      "Number of clean jokes in all=  2\n",
      "Number of all jokes with labels = 3363\n",
      "\n",
      "Total number of all jokes =  1691\n",
      "Number of clean jokes in all=  2\n",
      "Number of all jokes with labels = 1689\n",
      "\n",
      "Total number of all jokes =  1674\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_empty_label(df, 'all')\n",
    "print_empty_label(train, 'all')\n",
    "print_empty_label(test, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n",
      "['Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[3:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of jokes in each category\n",
    "def print_category_count(df, categories):\n",
    "    counts = []\n",
    "    for category in categories:\n",
    "        counts.append((category, df[category].sum()))\n",
    "    df_stats = pd.DataFrame(counts, columns=['category', 'number of jokes'])\n",
    "    print(df_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category  number of jokes\n",
      "0               Pun             1039\n",
      "1      Exaggeration              131\n",
      "2  Anthropomorphism              180\n",
      "3  Bridge_Inference              607\n",
      "4         Illogical              924\n",
      "5             Irony               82\n",
      "6         Imitation              258\n",
      "7            Others              588\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              778\n",
      "1      Exaggeration               71\n",
      "2  Anthropomorphism              140\n",
      "3  Bridge_Inference              316\n",
      "4         Illogical              438\n",
      "5             Irony               47\n",
      "6         Imitation              148\n",
      "7            Others              110\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              261\n",
      "1      Exaggeration               60\n",
      "2  Anthropomorphism               40\n",
      "3  Bridge_Inference              291\n",
      "4         Illogical              486\n",
      "5             Irony               35\n",
      "6         Imitation              110\n",
      "7            Others              478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_category_count(df, categories)\n",
    "print_category_count(train, categories)\n",
    "print_category_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df.iloc[:,3:].sum().values)\n",
    "\n",
    "    plt.title(\"Jokes in each category\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Joke Skill', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df.iloc[:,3:].sum().values\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_category_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Calculating number of jokes having multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_label(mlc_labels, multiLabel_counts):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax = sns.barplot(mlc_labels, multiLabel_counts.values)\n",
    "\n",
    "    plt.title(\"Jokes having multiple labels \")\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = multiLabel_counts.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_multiple_label(df):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    multiLabel_counts = rowSums.value_counts()\n",
    "    print(multiLabel_counts)\n",
    "    multiLabel_counts = multiLabel_counts.iloc[:]\n",
    "    #print(multiLabel_counts.index)\n",
    "    mlc_labels = ['L'+str(i) for i in multiLabel_counts.index]\n",
    "    print(mlc_labels)\n",
    "    \n",
    "    plot_multiple_label(mlc_labels, multiLabel_counts)\n",
    "    ##return(mlc_labels, multiLabel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2964\n",
      "2     355\n",
      "3      41\n",
      "4       3\n",
      "0       2\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L3', 'L4', 'L0']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_multiple_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. WordCloud representation of most used words in each category of jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import jieba\n",
    "import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, c in enumerate(categories):\\n    plt = MyWordCloud(plt, df, c, i+1)\\n\\n#plt.show()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40,25))\n",
    "\n",
    "def MyWordCloud(plt, df, field, position):\n",
    "    #subset = df[df.Pun==1]\n",
    "    subset = df.loc[df[field] == 1] # https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "    #print(subset.head()); exit\n",
    "    text = str(subset.Content.values)\n",
    "    words_list = jieba.lcut(Stopwords.clean_text(text))\n",
    "    text = Stopwords.clean_words(words_list)\n",
    "    cloud = WordCloud(\n",
    "                          #stopwords=STOPWORDS,\n",
    "                          stopwords=Stopwords.STOP_WORDS,\n",
    "                          background_color='black',\n",
    "                          font_path='SNsanafonGyou.ttf', # OSError: unknown file format\n",
    "                          collocations=False,\n",
    "                          width=2500,\n",
    "                          height=1800\n",
    "                         ).generate(\" \".join(text))\n",
    "\n",
    "    plt.subplot(3, 3, position)\n",
    "    plt.axis('off')\n",
    "    plt.title(field, fontsize=40)\n",
    "    plt.imshow(cloud)\n",
    "    return plt\n",
    "\n",
    "'''\n",
    "for i, c in enumerate(categories):\n",
    "    plt = MyWordCloud(plt, df, c, i+1)\n",
    "\n",
    "#plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in   all jokes: Max=2024, Min=10, Avg=134.07637444279345\n",
      "Number of characters in train jokes: Max=2024, Min=10, Avg=132.7906564163217\n",
      "Number of characters in  test jokes: Max=874, Min=12, Avg=135.3751493428913\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = df.Content.map(len)\n",
    "print(f'Number of characters in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(len)\n",
    "print(f'Number of characters in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(len)\n",
    "print(f'Number of characters in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set global variables: data\n",
    "data = df\n",
    "#data = df.loc[np.random.choice(df.index, size=3365)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stopwords # import my own module with STOP_WORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    Given a raw text string, return a clean text string.\n",
    "    Example: \n",
    "        input:  \"Years  passed. 多少   年过 去 了 。  \"\n",
    "        output: \"years passed.多少年过去了。\"\n",
    "    '''\n",
    "    text = str(text)\n",
    "    text = text.lower() # 'years  passed. 多少   年过 去 了 。'\n",
    "    # Next line will remove redundant white space for jeiba to cut\n",
    "    text = re.sub(r'\\s+([^a-zA-Z0-9.])', r'\\1', text) # years passed.多少年过去了。\n",
    "# see: https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_words(text, RmvStopWord=True, RmvMark=True):\n",
    "    words = jieba.lcut(text)\n",
    "#    print(\"After jieba.lcut():\", words)\n",
    "#    WL = [ w \n",
    "    WL = [ ps.stem(w)\n",
    "#    WL = [ wnl.lemmatize(w)\n",
    "        for w in words \n",
    "          if (not re.match(r'\\s', w)) # remove white spaces\n",
    "            and (RmvMark==False or not re.match(r'\\W', w)) # remove punctuations\n",
    "#            and (RmvMark==False or not re.match('^[a-z_]$', w)) # remove punctuations\n",
    "#            and (RmvMark==False or w not in PUNCTUATIONS)\n",
    "            and (RmvStopWord==False or w not in Stopwords.STOP_WORDS)\n",
    "            and (not re.match(r'^\\d+$', w)) # remove digit\n",
    "         ]\n",
    "    WL = \" \".join(WL)\n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/kg/jcdj05xn20144cv9kwywp26r0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Title                                            Content  Pun  \\\n",
      "0  L0001  要求加薪  員工：老闆，您必須幫我加薪，已經有三家公司在找我了！     老闆：哪三家？     員工：...    1   \n",
      "1  L0002  查無此人  某市政府辦公大樓落成，門口缺副對聯。     副市長揮毫     上聯：說實話辦實事一身正氣...    0   \n",
      "2  L0003   遣散費  中午老闆視察自己的建築工地時，發現有個人在角落玩手機。     老闆：你月薪多少？     ...    0   \n",
      "3  L0004  職業習慣  一天，一位法官的女友看見兩個蚊子，便叫法官打死。     只見法官只把那個肚子飽飽的蚊子打死...    1   \n",
      "4  L0005  美女吵架  辦公室中兩位女同事吵起來了。     經理忍無可忍：「太不像話了！現在是什麼情況？你們把原因...    0   \n",
      "\n",
      "   Exaggeration  Anthropomorphism  Bridge_Inference  Illogical  Irony  \\\n",
      "0             0                 0                 0          0      0   \n",
      "1             0                 0                 0          0      1   \n",
      "2             0                 0                 0          0      0   \n",
      "3             0                 1                 0          0      0   \n",
      "4             0                 0                 1          0      0   \n",
      "\n",
      "   Imitation  Others  \n",
      "0          0       0  \n",
      "1          0       0  \n",
      "2          1       0  \n",
      "3          1       0  \n",
      "4          0       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.641 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data['Content'] = data['Content'].str.lower()\n",
    "#data['Content'] = data['Content'].apply(cleanHtml)\n",
    "#data['Content'] = data['Content'].apply(cleanPunc)\n",
    "#data['Content'] = data['Content'].apply(keepAlpha)\n",
    "data['Content'] = data['Content'].apply(clean_text)\n",
    "data['Content'] = data['Content'].apply(clean_words)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['Content'] = data['Content'].apply(removeStopWords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pun</th>\n",
       "      <th>Exaggeration</th>\n",
       "      <th>Anthropomorphism</th>\n",
       "      <th>Bridge_Inference</th>\n",
       "      <th>Illogical</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Imitation</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0001</td>\n",
       "      <td>要求加薪</td>\n",
       "      <td>員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0002</td>\n",
       "      <td>查無此人</td>\n",
       "      <td>某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0003</td>\n",
       "      <td>遣散費</td>\n",
       "      <td>中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0004</td>\n",
       "      <td>職業習慣</td>\n",
       "      <td>一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0005</td>\n",
       "      <td>美女吵架</td>\n",
       "      <td>辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Title                                            Content  Pun  \\\n",
       "0  L0001  要求加薪  員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...    1   \n",
       "1  L0002  查無此人  某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...    0   \n",
       "2  L0003   遣散費  中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...    0   \n",
       "3  L0004  職業習慣  一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...    1   \n",
       "4  L0005  美女吵架  辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...    0   \n",
       "\n",
       "   Exaggeration  Anthropomorphism  Bridge_Inference  Illogical  Irony  \\\n",
       "0             0                 0                 0          0      0   \n",
       "1             0                 0                 0          0      1   \n",
       "2             0                 0                 0          0      0   \n",
       "3             0                 1                 0          0      0   \n",
       "4             0                 0                 1          0      0   \n",
       "\n",
       "   Imitation  Others  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          1       0  \n",
       "3          1       0  \n",
       "4          0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['Content'] = data['Content'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 11)\n",
      "(1674, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set global variables: train, test\n",
    "#train, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n",
    "train, test = train_test_split(data, random_state=42, train_size=1691, shuffle=False)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables: train_text, test_text\n",
    "train_text = train['Content']\n",
    "test_text = test['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in   all jokes: Max=491, Min=3, Avg=41.6222882615156\n",
      "Number of words in train jokes: Max=491, Min=3, Avg=40.33234772324069\n",
      "Number of words in  test jokes: Max=290, Min=4, Avg=42.92532855436081\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = data.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['ID', 'Title', 'Content'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['ID', 'Title', 'Content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_tfidf.shape:(1691, 9559), xtest_tfidf.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram.shape:(1691, 9559), xtest_tfidf_ngram.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram_chars.shape:(1691, 9559), xtest_tfidf_ngram_chars.shape: (1674, 9559)\n",
      "It takes 2.51 seconds to convert 3 TFxIDF vectors.\n"
     ]
    }
   ],
   "source": [
    "time_TfidfVector = time.time()\n",
    "\n",
    "def Create_TFxIDF(data_text, train_text, test_text):\n",
    "\n",
    "# word level tf-idf\n",
    "    #tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2, max_features=10000)\n",
    "    tfidf_vect.fit(data_text)\n",
    "    xtrain_tfidf = tfidf_vect.transform(train_text)\n",
    "    xtest_tfidf = tfidf_vect.transform(test_text)\n",
    "    print(f\"xtrain_tfidf.shape:{xtrain_tfidf.shape}, xtest_tfidf.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# word level ngram tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram.fit(data_text)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    print(f\"xtrain_tfidf_ngram.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# character level ngram tf-idf\n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram_chars.fit(data_text)\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "    xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) \n",
    "    print(f\"xtrain_tfidf_ngram_chars.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram_chars.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert 3 TFxIDF vectors.\"%(time.time()-time_TfidfVector))\n",
    "\n",
    "    return (xtrain_tfidf, xtest_tfidf, \n",
    "             xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    "             xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    "            tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars)\n",
    "\n",
    "(xtrain_tfidf, xtest_tfidf, \n",
    " xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    " xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    " tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars) = Create_TFxIDF(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9559) (1674, 9559)\n"
     ]
    }
   ],
   "source": [
    "# re-assign x_train and x_test to what we want\n",
    "x_train, x_test, vectorizer = xtrain_tfidf, xtest_tfidf, tfidf_vect\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram, xtest_tfidf_ngram, tfidf_vect_ngram\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars, tfidf_vect_ngram_chars\n",
    "print(x_train.shape, x_test.shape)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def tcfunc(x, n=4): # trancate a number to have n decimal digits\n",
    "    d = '0' * n\n",
    "    d = int('1' + d)\n",
    "# https://stackoverflow.com/questions/4541155/check-if-a-number-is-int-or-float\n",
    "    if isinstance(x, (int, float)): return int(x * d) / d\n",
    "    return x\n",
    "\n",
    "def print_cls_report(y_true, prediction):\n",
    "    print('Test accuracy is %1.4f'%(accuracy_score(y_true, prediction)))\n",
    "\n",
    "    print(classification_report(y_true, prediction))\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"\\tPrecision\\tRecall\\tF1\\tSupport\")\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='micro')))\n",
    "    print(\"Micro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='macro')))\n",
    "    print(\"Macro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    \n",
    "#    if True:\n",
    "    if False:\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        try: \n",
    "            print(classification_report(y_true, prediction, digits=4))\n",
    "        except ValueError:\n",
    "            print('May be some category has no predicted samples')\n",
    "        show_confusion_matrix(prediction)\n",
    "\n",
    "\n",
    "    print(f'y_true.shape={y_true.shape}, prediction.shape={prediction.shape}')\n",
    "    #print(y_true.head())\n",
    "    #print(prediction[0:6])\n",
    "\n",
    "    # https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python\n",
    "    pred = prediction\n",
    "    if not isinstance(pred, np.ndarray): pred = prediction.toarray()\n",
    "    print(type(y_true), type(prediction), type(pred))\n",
    "    try:\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "        print('macro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='macro'))) # default average=’macro’\n",
    "        print('micro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='micro')))\n",
    "    except:\n",
    "        print(\"roc_auc_score error!!!\")\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, pred)\n",
    "        print(f'fpr={fpr}\\ntpr={tpr}\\nthresholds={thresholds}')\n",
    "    except:\n",
    "        print('roc_curve error!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Processing Pun jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1413\n",
      "           1       0.43      0.27      0.33       261\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1674\n",
      "   macro avg       0.65      0.60      0.62      1674\n",
      "weighted avg       0.81      0.83      0.81      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8309\t0.8309\t0.8309\tNone\n",
      "Macro\t0.6535\t0.6031\t0.6186\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.6031\n",
      "micro roc_auc_score is 0.6031\n",
      "fpr=[0.         0.06581741 1.        ]\n",
      "tpr=[0.         0.27203065 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Exaggeration jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1614\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1674\n",
      "   macro avg       0.48      0.50      0.49      1674\n",
      "weighted avg       0.93      0.96      0.95      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9641\t0.9641\t0.9641\tNone\n",
      "Macro\t0.482\t0.5\t0.4908\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Anthropomorphism jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1634\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1674\n",
      "   macro avg       0.49      0.50      0.49      1674\n",
      "weighted avg       0.95      0.98      0.96      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9761\t0.9761\t0.9761\tNone\n",
      "Macro\t0.488\t0.5\t0.4939\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Bridge_Inference jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90      1383\n",
      "           1       0.00      0.00      0.00       291\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1674\n",
      "   macro avg       0.41      0.50      0.45      1674\n",
      "weighted avg       0.68      0.83      0.75      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8261\t0.8261\t0.8261\tNone\n",
      "Macro\t0.413\t0.5\t0.4524\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Illogical jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1188\n",
      "           1       0.60      0.01      0.01       486\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1674\n",
      "   macro avg       0.66      0.50      0.42      1674\n",
      "weighted avg       0.68      0.71      0.59      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.7102\t0.7102\t0.7102\tNone\n",
      "Macro\t0.6553\t0.5022\t0.4212\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5022\n",
      "micro roc_auc_score is 0.5022\n",
      "fpr=[0.        0.0016835 1.       ]\n",
      "tpr=[0.         0.00617284 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Irony jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1639\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1674\n",
      "   macro avg       0.49      0.50      0.49      1674\n",
      "weighted avg       0.96      0.98      0.97      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.979\t0.979\t0.979\tNone\n",
      "Macro\t0.4895\t0.5\t0.4947\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Imitation jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1564\n",
      "           1       0.00      0.00      0.00       110\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1674\n",
      "   macro avg       0.47      0.50      0.48      1674\n",
      "weighted avg       0.87      0.93      0.90      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9342\t0.9342\t0.9342\tNone\n",
      "Macro\t0.4671\t0.5\t0.483\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Others jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.7145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1196\n",
      "           1       0.00      0.00      0.00       478\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1674\n",
      "   macro avg       0.36      0.50      0.42      1674\n",
      "weighted avg       0.51      0.71      0.60      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.7144\t0.7144\t0.7144\tNone\n",
      "Macro\t0.3572\t0.5\t0.4167\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n",
      "CPU times: user 132 ms, sys: 87.5 ms, total: 220 ms\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "#for category in categories:\n",
    "for category in categories:\n",
    "    printmd('**Processing {} jokes...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    \n",
    "    print_cls_report(test[category], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Multiple Binary Classifications - (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use binary relevance, run \"pip install scikit-multilearn\" in advance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Next line refers to: http://scikit.ml/tutorial.html\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with GaussianNB()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.0980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.40      0.27       261\n",
      "           1       0.04      0.02      0.02        60\n",
      "           2       0.10      0.07      0.09        40\n",
      "           3       0.15      0.08      0.11       291\n",
      "           4       0.29      0.22      0.25       486\n",
      "           5       0.33      0.03      0.05        35\n",
      "           6       0.07      0.05      0.05       110\n",
      "           7       0.17      0.01      0.01       478\n",
      "\n",
      "   micro avg       0.21      0.14      0.17      1761\n",
      "   macro avg       0.17      0.11      0.11      1761\n",
      "weighted avg       0.20      0.14      0.14      1761\n",
      " samples avg       0.12      0.14      0.12      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2112\t0.1402\t0.1686\tNone\n",
      "Macro\t0.1702\t0.1088\t0.1073\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5118\n",
      "micro roc_auc_score is 0.5305\n",
      "roc_curve error!!!\n",
      "CPU times: user 12.4 s, sys: 848 ms, total: 13.2 s\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "#   with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with GaussianNB()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with LinearSVC()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.20      0.23      0.21        40\n",
      "           3       0.25      0.18      0.21       291\n",
      "           4       0.32      0.33      0.32       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.09      0.05      0.06       110\n",
      "           7       0.23      0.01      0.01       478\n",
      "\n",
      "   micro avg       0.26      0.19      0.22      1761\n",
      "   macro avg       0.17      0.15      0.14      1761\n",
      "weighted avg       0.24      0.19      0.18      1761\n",
      " samples avg       0.17      0.19      0.18      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2643\t0.193\t0.2231\tNone\n",
      "Macro\t0.1671\t0.1516\t0.1414\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5314\n",
      "micro roc_auc_score is 0.5559\n",
      "roc_curve error!!!\n",
      "CPU times: user 1.53 s, sys: 180 ms, total: 1.71 s\n",
      "Wall time: 709 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Next line refers to: http://scikit.ml/tutorial.html and \n",
    "#   http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "#classifier = BinaryRelevance(classifier=SVC(), require_dense=[False, True]) # 0.5 very bad!\n",
    "# https://scikit-learn.org/stable/modules/svm.html#unbalanced-problems\n",
    "classifier = BinaryRelevance(classifier=LinearSVC(class_weight='balanced')) # 0.5314\n",
    "#classifier = BinaryRelevance(classifier=LinearSVC()) # Test roc_auc_score is 0.5234\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with LinearSVC()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Classifier Chains with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.2264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.23      0.23      0.23        40\n",
      "           3       0.21      0.34      0.26       291\n",
      "           4       0.31      0.45      0.37       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.12      0.06      0.08       110\n",
      "           7       0.25      0.02      0.04       478\n",
      "\n",
      "   micro avg       0.26      0.26      0.26      1761\n",
      "   macro avg       0.17      0.19      0.16      1761\n",
      "weighted avg       0.24      0.26      0.21      1761\n",
      " samples avg       0.26      0.26      0.25      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2554\t0.2583\t0.2569\tNone\n",
      "Macro\t0.1702\t0.1911\t0.1606\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5327\n",
      "micro roc_auc_score is 0.5722\n",
      "roc_curve error!!!\n",
      "CPU times: user 2.93 s, sys: 917 ms, total: 3.85 s\n",
      "Wall time: 2.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "#classifier = ClassifierChain(LogisticRegression()) # Test roc_auc_score is 0.5159\n",
    "classifier = ClassifierChain(LinearSVC(class_weight='balanced')) #  0.5327\n",
    "\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Classifier Chains with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Label Powerset with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.30       261\n",
      "           1       0.05      0.12      0.07        60\n",
      "           2       0.12      0.62      0.20        40\n",
      "           3       0.22      0.25      0.24       291\n",
      "           4       0.29      0.35      0.32       486\n",
      "           5       0.03      0.09      0.05        35\n",
      "           6       0.08      0.23      0.11       110\n",
      "           7       0.35      0.10      0.15       478\n",
      "\n",
      "   micro avg       0.20      0.27      0.23      1761\n",
      "   macro avg       0.17      0.28      0.18      1761\n",
      "weighted avg       0.25      0.27      0.23      1761\n",
      " samples avg       0.21      0.27      0.23      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.1989\t0.2674\t0.2281\tNone\n",
      "Macro\t0.1699\t0.2775\t0.1795\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5541\n",
      "micro roc_auc_score is 0.5522\n",
      "roc_curve error!!!\n",
      "CPU times: user 1.01 s, sys: 52.5 ms, total: 1.06 s\n",
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "#classifier = LabelPowerset(LogisticRegression()) # Test roc_auc_score is 0.5059\n",
    "classifier = LabelPowerset(LinearSVC(class_weight='balanced')) # 0.5541\n",
    "# Test roc_auc_score is 0.5312 if xtrain_tfidf_ngram, xtest_tfidf_ngram are used.\n",
    "# Test roc_auc_score is 0.5474 if xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars are used\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Label Powerset with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out/Skill_True.txt', 'w') as outF:\n",
    "    outF.write(y_test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "with open('out/Skill_Pred.txt', 'w') as outF:\n",
    "    outF.write(pd.DataFrame(predictions.toarray(), columns=list(y_test.columns)).to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Adapted Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MLkNN**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.0998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.29       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.25      0.07      0.12        40\n",
      "           3       0.24      0.05      0.08       291\n",
      "           4       0.33      0.15      0.20       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00       110\n",
      "           7       0.00      0.00      0.00       478\n",
      "\n",
      "   micro avg       0.27      0.11      0.15      1761\n",
      "   macro avg       0.13      0.08      0.09      1761\n",
      "weighted avg       0.17      0.11      0.11      1761\n",
      " samples avg       0.11      0.11      0.11      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2652\t0.1061\t0.1516\tNone\n",
      "Macro\t0.1324\t0.081\t0.0861\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5164\n",
      "micro roc_auc_score is 0.5308\n",
      "roc_curve error!!!\n",
      "CPU times: user 1min 9s, sys: 247 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_new = MLkNN(k=10)\n",
    "\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "\n",
    "printmd('**MLkNN**')\n",
    "print_cls_report(y_test, predictions_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
