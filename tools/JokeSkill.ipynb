{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Approaches to Multi-Label Classification\n",
    "\n",
    "This program is modified from https://github.com/nkartik94/Multi-Label-Text-Classification\n",
    "on 2019/11/18 by Yuen-Hsien Tseng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "#printmd('**bold**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../mlabel_corpora/JokeSkill.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 11)\n"
     ]
    }
   ],
   "source": [
    "# set global variables: df\n",
    "df = pd.read_csv(data_path, delimiter=\"\\t\")\n",
    "#data_raw = df.loc[np.random.choice(data_raw.index, size=2000)]\n",
    "print(df.shape) # same as data_raw.shape in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 11)\n",
      "(1674, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ID=L1850 為分界，之前：吳玟萱，之後：黃亭筠，均為中文系同一屆\n",
    "train, test = train_test_split(df, train_size=1691, shuffle=False) \n",
    "# (tempararily) set global variables: train, test \n",
    "\n",
    "#with open('mlabel_corpora/JokeSkill_train.txt', 'w') as outF:\n",
    "#    outF.write(train.to_csv(sep='\\t', index=False))\n",
    "\n",
    "#with open('mlabel_corpora/JokeSkill_test.txt', 'w') as outF:\n",
    "#    outF.write(test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf[\\'Content\\'] = df[df.columns[1:3]].apply(\\n    lambda x: \\' 。 \\'.join(x.dropna().astype(str)),\\n    axis=1\\n)\\nprint(\"Number of rows in data =\",df.shape[0])\\nprint(\"Number of columns in data =\",df.shape[1])\\nprint(\"\\n\")\\nprintmd(\"**Sample data:**\")\\ndf.head()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not do this, because there are many duplicate titles\n",
    "# Merge Title into Content\n",
    "'''\n",
    "df['Content'] = df[df.columns[1:3]].apply(\n",
    "    lambda x: ' 。 '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Number of rows in data =\",df.shape[0])\n",
    "print(\"Number of columns in data =\",df.shape[1])\n",
    "print(\"\\n\")\n",
    "printmd(\"**Sample data:**\")\n",
    "df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                  0\n",
      "Title               0\n",
      "Content             0\n",
      "Pun                 0\n",
      "Exaggeration        0\n",
      "Anthropomorphism    0\n",
      "Bridge_Inference    0\n",
      "Illogical           0\n",
      "Irony               0\n",
      "Imitation           0\n",
      "Others              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_check = df.isnull().sum()\n",
    "print(missing_values_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculating number of jokes under each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jokes with no label are considered to be clean jokes.\n",
    "# Creating seperate column in dataframe to identify clean jokes.\n",
    "# We use axis=1 to count row-wise and axis=0 to count column wise\n",
    "def print_empty_label(df, s):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    #print(rowSums.shape)\n",
    "    #print(rowSums.head())\n",
    "    clean_comments_count = (rowSums==0).sum(axis=0)\n",
    "\n",
    "    print(f\"Total number of {s} jokes = \",len(df))\n",
    "    print(f\"Number of clean jokes in {s}= \",clean_comments_count)\n",
    "    print(f\"Number of {s} jokes with labels =\",(len(df)-clean_comments_count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of all jokes =  3365\n",
      "Number of clean jokes in all=  2\n",
      "Number of all jokes with labels = 3363\n",
      "\n",
      "Total number of all jokes =  1691\n",
      "Number of clean jokes in all=  2\n",
      "Number of all jokes with labels = 1689\n",
      "\n",
      "Total number of all jokes =  1674\n",
      "Number of clean jokes in all=  0\n",
      "Number of all jokes with labels = 1674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_empty_label(df, 'all')\n",
    "print_empty_label(train, 'all')\n",
    "print_empty_label(test, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Title', 'Content', 'Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n",
      "['Pun', 'Exaggeration', 'Anthropomorphism', 'Bridge_Inference', 'Illogical', 'Irony', 'Imitation', 'Others']\n"
     ]
    }
   ],
   "source": [
    "# set global variables: categories\n",
    "categories = list(df.columns.values)\n",
    "print(categories)\n",
    "categories = categories[3:]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of jokes in each category\n",
    "def print_category_count(df, categories):\n",
    "    counts = []\n",
    "    for category in categories:\n",
    "        counts.append((category, df[category].sum()))\n",
    "    df_stats = pd.DataFrame(counts, columns=['category', 'number of jokes'])\n",
    "    print(df_stats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           category  number of jokes\n",
      "0               Pun             1039\n",
      "1      Exaggeration              131\n",
      "2  Anthropomorphism              180\n",
      "3  Bridge_Inference              607\n",
      "4         Illogical              924\n",
      "5             Irony               82\n",
      "6         Imitation              258\n",
      "7            Others              588\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              778\n",
      "1      Exaggeration               71\n",
      "2  Anthropomorphism              140\n",
      "3  Bridge_Inference              316\n",
      "4         Illogical              438\n",
      "5             Irony               47\n",
      "6         Imitation              148\n",
      "7            Others              110\n",
      "\n",
      "           category  number of jokes\n",
      "0               Pun              261\n",
      "1      Exaggeration               60\n",
      "2  Anthropomorphism               40\n",
      "3  Bridge_Inference              291\n",
      "4         Illogical              486\n",
      "5             Irony               35\n",
      "6         Imitation              110\n",
      "7            Others              478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_category_count(df, categories)\n",
    "print_category_count(train, categories)\n",
    "print_category_count(test, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_count(df, categories):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax= sns.barplot(categories, df.iloc[:,3:].sum().values)\n",
    "\n",
    "    plt.title(\"Jokes in each category\", fontsize=24)\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Joke Skill', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    #print(rects)\n",
    "    labels = df.iloc[:,3:].sum().values\n",
    "    #print(labels)\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_category_count(df, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Calculating number of jokes having multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_label(mlc_labels, multiLabel_counts):\n",
    "    sns.set(font_scale = 2)\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    ax = sns.barplot(mlc_labels, multiLabel_counts.values)\n",
    "\n",
    "    plt.title(\"Jokes having multiple labels \")\n",
    "    plt.ylabel('Number of jokes', fontsize=18)\n",
    "    plt.xlabel('Number of labels', fontsize=18)\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = multiLabel_counts.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_multiple_label(df):\n",
    "    rowSums = df.iloc[:,3:].sum(axis=1)\n",
    "    multiLabel_counts = rowSums.value_counts()\n",
    "    print(multiLabel_counts)\n",
    "    multiLabel_counts = multiLabel_counts.iloc[:]\n",
    "    #print(multiLabel_counts.index)\n",
    "    mlc_labels = ['L'+str(i) for i in multiLabel_counts.index]\n",
    "    print(mlc_labels)\n",
    "    \n",
    "    plot_multiple_label(mlc_labels, multiLabel_counts)\n",
    "    ##return(mlc_labels, multiLabel_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2964\n",
      "2     355\n",
      "3      41\n",
      "4       3\n",
      "0       2\n",
      "dtype: int64\n",
      "['L1', 'L2', 'L3', 'L4', 'L0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samm1/anaconda3/envs/WoS/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_multiple_label(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. WordCloud representation of most used words in each category of jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import jieba\n",
    "import Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, c in enumerate(categories):\\n    plt = MyWordCloud(plt, df, c, i+1)\\n\\n#plt.show()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40,25))\n",
    "\n",
    "def MyWordCloud(plt, df, field, position):\n",
    "    #subset = df[df.Pun==1]\n",
    "    subset = df.loc[df[field] == 1] # https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "    #print(subset.head()); exit\n",
    "    text = str(subset.Content.values)\n",
    "    words_list = jieba.lcut(Stopwords.clean_text(text))\n",
    "    text = Stopwords.clean_words(words_list)\n",
    "    cloud = WordCloud(\n",
    "                          #stopwords=STOPWORDS,\n",
    "                          stopwords=Stopwords.STOP_WORDS,\n",
    "                          background_color='black',\n",
    "                          font_path='SNsanafonGyou.ttf', # OSError: unknown file format\n",
    "                          collocations=False,\n",
    "                          width=2500,\n",
    "                          height=1800\n",
    "                         ).generate(\" \".join(text))\n",
    "\n",
    "    plt.subplot(3, 3, position)\n",
    "    plt.axis('off')\n",
    "    plt.title(field, fontsize=40)\n",
    "    plt.imshow(cloud)\n",
    "    return plt\n",
    "\n",
    "'''\n",
    "for i, c in enumerate(categories):\n",
    "    plt = MyWordCloud(plt, df, c, i+1)\n",
    "\n",
    "#plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in   all jokes: Max=2024, Min=10, Avg=134.07637444279345\n",
      "Number of characters in train jokes: Max=2024, Min=10, Avg=132.7906564163217\n",
      "Number of characters in  test jokes: Max=874, Min=12, Avg=135.3751493428913\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = df.Content.map(len)\n",
    "print(f'Number of characters in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(len)\n",
    "print(f'Number of characters in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(len)\n",
    "print(f'Number of characters in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set global variables: data\n",
    "data = df\n",
    "#data = df.loc[np.random.choice(df.index, size=3365)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stopwords # import my own module with STOP_WORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    '''\n",
    "    Given a raw text string, return a clean text string.\n",
    "    Example: \n",
    "        input:  \"Years  passed. 多少   年过 去 了 。  \"\n",
    "        output: \"years passed.多少年过去了。\"\n",
    "    '''\n",
    "    text = str(text)\n",
    "    text = text.lower() # 'years  passed. 多少   年过 去 了 。'\n",
    "    # Next line will remove redundant white space for jeiba to cut\n",
    "    text = re.sub(r'\\s+([^a-zA-Z0-9.])', r'\\1', text) # years passed.多少年过去了。\n",
    "# see: https://stackoverflow.com/questions/16720541/python-string-replace-regular-expression\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def clean_words(text, RmvStopWord=True, RmvMark=True):\n",
    "    words = jieba.lcut(text)\n",
    "#    print(\"After jieba.lcut():\", words)\n",
    "#    WL = [ w \n",
    "    WL = [ ps.stem(w)\n",
    "#    WL = [ wnl.lemmatize(w)\n",
    "        for w in words \n",
    "          if (not re.match(r'\\s', w)) # remove white spaces\n",
    "            and (RmvMark==False or not re.match(r'\\W', w)) # remove punctuations\n",
    "#            and (RmvMark==False or not re.match('^[a-z_]$', w)) # remove punctuations\n",
    "#            and (RmvMark==False or w not in PUNCTUATIONS)\n",
    "            and (RmvStopWord==False or w not in Stopwords.STOP_WORDS)\n",
    "            and (not re.match(r'^\\d+$', w)) # remove digit\n",
    "         ]\n",
    "    WL = \" \".join(WL)\n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jh/lksld56x4_10wxpq687st0x80000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID Title                                            Content  Pun  \\\n",
      "0  L0001  要求加薪  員工：老闆，您必須幫我加薪，已經有三家公司在找我了！     老闆：哪三家？     員工：...    1   \n",
      "1  L0002  查無此人  某市政府辦公大樓落成，門口缺副對聯。     副市長揮毫     上聯：說實話辦實事一身正氣...    0   \n",
      "2  L0003   遣散費  中午老闆視察自己的建築工地時，發現有個人在角落玩手機。     老闆：你月薪多少？     ...    0   \n",
      "3  L0004  職業習慣  一天，一位法官的女友看見兩個蚊子，便叫法官打死。     只見法官只把那個肚子飽飽的蚊子打死...    1   \n",
      "4  L0005  美女吵架  辦公室中兩位女同事吵起來了。     經理忍無可忍：「太不像話了！現在是什麼情況？你們把原因...    0   \n",
      "\n",
      "   Exaggeration  Anthropomorphism  Bridge_Inference  Illogical  Irony  \\\n",
      "0             0                 0                 0          0      0   \n",
      "1             0                 0                 0          0      1   \n",
      "2             0                 0                 0          0      0   \n",
      "3             0                 1                 0          0      0   \n",
      "4             0                 0                 1          0      0   \n",
      "\n",
      "   Imitation  Others  \n",
      "0          0       0  \n",
      "1          0       0  \n",
      "2          1       0  \n",
      "3          1       0  \n",
      "4          0       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.431 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "data['Content'] = data['Content'].str.lower()\n",
    "#data['Content'] = data['Content'].apply(cleanHtml)\n",
    "#data['Content'] = data['Content'].apply(cleanPunc)\n",
    "#data['Content'] = data['Content'].apply(keepAlpha)\n",
    "data['Content'] = data['Content'].apply(clean_text)\n",
    "data['Content'] = data['Content'].apply(clean_words)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "data['Content'] = data['Content'].apply(removeStopWords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Pun</th>\n",
       "      <th>Exaggeration</th>\n",
       "      <th>Anthropomorphism</th>\n",
       "      <th>Bridge_Inference</th>\n",
       "      <th>Illogical</th>\n",
       "      <th>Irony</th>\n",
       "      <th>Imitation</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0001</td>\n",
       "      <td>要求加薪</td>\n",
       "      <td>員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0002</td>\n",
       "      <td>查無此人</td>\n",
       "      <td>某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0003</td>\n",
       "      <td>遣散費</td>\n",
       "      <td>中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0004</td>\n",
       "      <td>職業習慣</td>\n",
       "      <td>一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0005</td>\n",
       "      <td>美女吵架</td>\n",
       "      <td>辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Title                                            Content  Pun  \\\n",
       "0  L0001  要求加薪  員工 老 闆 必須 幫 加薪 已經 三家 公司 找 老 闆 三家 員工 自來 水 公司 台電...    1   \n",
       "1  L0002  查無此人  某 市政府 辦公大樓 落成 門口 缺 副 對聯 副 市長 揮 毫上 聯 實話 辦實事 一身 ...    0   \n",
       "2  L0003   遣散費  中午 老 闆 視察 自己 建築 工地 時 發現 個 人 角落 玩手 機 老 闆 月薪 多少 ...    0   \n",
       "3  L0004  職業習慣  一天 一位 法官 女友 看見 兩個 蚊子 便 叫 法官 打死 只見 法官 只 那個 肚子 飽...    1   \n",
       "4  L0005  美女吵架  辦 公室 中 兩位 女同事 吵起 經理 忍無可忍 太不像 話 情況 原因 給我 清楚 兩人 ...    0   \n",
       "\n",
       "   Exaggeration  Anthropomorphism  Bridge_Inference  Illogical  Irony  \\\n",
       "0             0                 0                 0          0      0   \n",
       "1             0                 0                 0          0      1   \n",
       "2             0                 0                 0          0      0   \n",
       "3             0                 1                 0          0      0   \n",
       "4             0                 0                 1          0      0   \n",
       "\n",
       "   Imitation  Others  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          1       0  \n",
       "3          1       0  \n",
       "4          0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "data['Content'] = data['Content'].apply(stemming)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 11)\n",
      "(1674, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set global variables: train, test\n",
    "#train, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n",
    "train, test = train_test_split(data, random_state=42, train_size=1691, shuffle=False)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables: train_text, test_text\n",
    "train_text = train['Content']\n",
    "test_text = test['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in   all jokes: Max=491, Min=3, Avg=41.621991084695395\n",
      "Number of words in train jokes: Max=491, Min=3, Avg=40.33234772324069\n",
      "Number of words in  test jokes: Max=290, Min=4, Avg=42.924731182795696\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics of the dataset: MaxLength, MinLength, AvgChars, AvgWords\n",
    "Len = data.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in   all jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = train.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in train jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')\n",
    "Len = test.Content.map(lambda x: len(x.split()))\n",
    "print(f'Number of words in  test jokes: Max={max(Len)}, Min={min(Len)}, Avg={sum(Len)/len(Len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,2), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "\n",
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = ['ID', 'Title', 'Content'], axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = ['ID', 'Title', 'Content'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain_tfidf.shape:(1691, 9559), xtest_tfidf.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram.shape:(1691, 9559), xtest_tfidf_ngram.shape: (1674, 9559)\n",
      "xtrain_tfidf_ngram_chars.shape:(1691, 9559), xtest_tfidf_ngram_chars.shape: (1674, 9559)\n",
      "It takes 1.94 seconds to convert 3 TFxIDF vectors.\n"
     ]
    }
   ],
   "source": [
    "time_TfidfVector = time.time()\n",
    "\n",
    "def Create_TFxIDF(data_text, train_text, test_text):\n",
    "\n",
    "# word level tf-idf\n",
    "    #tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "        stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2, max_features=10000)\n",
    "    tfidf_vect.fit(data_text)\n",
    "    xtrain_tfidf = tfidf_vect.transform(train_text)\n",
    "    xtest_tfidf = tfidf_vect.transform(test_text)\n",
    "    print(f\"xtrain_tfidf.shape:{xtrain_tfidf.shape}, xtest_tfidf.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# word level ngram tf-idf \n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram.fit(data_text)\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_text)\n",
    "    xtest_tfidf_ngram =  tfidf_vect_ngram.transform(test_text)\n",
    "    print(f\"xtrain_tfidf_ngram.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "# character level ngram tf-idf\n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', \n",
    "                    stop_words=Stopwords.STOP_WORDS, max_df=0.95, min_df=2,\n",
    "                    ngram_range=(2,3), max_features=10000)\n",
    "    tfidf_vect_ngram_chars.fit(data_text)\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_text) \n",
    "    xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(test_text) \n",
    "    print(f\"xtrain_tfidf_ngram_chars.shape:{xtrain_tfidf.shape}, xtest_tfidf_ngram_chars.shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "    print(\"It takes %4.2f seconds to convert 3 TFxIDF vectors.\"%(time.time()-time_TfidfVector))\n",
    "\n",
    "    return (xtrain_tfidf, xtest_tfidf, \n",
    "             xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    "             xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    "            tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars)\n",
    "\n",
    "(xtrain_tfidf, xtest_tfidf, \n",
    " xtrain_tfidf_ngram, xtest_tfidf_ngram,\n",
    " xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars,\n",
    " tfidf_vect, tfidf_vect_ngram, tfidf_vect_ngram_chars) = Create_TFxIDF(data.Content, train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1691, 9559) (1674, 9559)\n"
     ]
    }
   ],
   "source": [
    "# re-assign x_train and x_test to what we want\n",
    "x_train, x_test, vectorizer = xtrain_tfidf, xtest_tfidf, tfidf_vect\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram, xtest_tfidf_ngram, tfidf_vect_ngram\n",
    "#x_train, x_test, vectorizer = xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars, tfidf_vect_ngram_chars\n",
    "print(x_train.shape, x_test.shape)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple Binary Classifications - (One Vs Rest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation metrics\n",
    "def tcfunc(x, n=4): # trancate a number to have n decimal digits\n",
    "    d = '0' * n\n",
    "    d = int('1' + d)\n",
    "# https://stackoverflow.com/questions/4541155/check-if-a-number-is-int-or-float\n",
    "    if isinstance(x, (int, float)): return int(x * d) / d\n",
    "    return x\n",
    "\n",
    "def print_cls_report(y_true, prediction):\n",
    "    print('Test accuracy is %1.4f'%(accuracy_score(y_true, prediction)))\n",
    "\n",
    "    print(classification_report(y_true, prediction))\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    print(\"\\tPrecision\\tRecall\\tF1\\tSupport\")\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='micro')))\n",
    "    print(\"Micro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "\n",
    "    (Precision, Recall, F1, Support) = list(map(tcfunc, \n",
    "        precision_recall_fscore_support(y_true, prediction, average='macro')))\n",
    "    print(\"Macro\\t{}\\t{}\\t{}\\t{}\".format(Precision, Recall, F1, Support))\n",
    "    \n",
    "#    if True:\n",
    "    if False:\n",
    "        print(confusion_matrix(y_true, prediction))\n",
    "        try: \n",
    "            print(classification_report(y_true, prediction, digits=4))\n",
    "        except ValueError:\n",
    "            print('May be some category has no predicted samples')\n",
    "        show_confusion_matrix(prediction)\n",
    "\n",
    "\n",
    "    print(f'y_true.shape={y_true.shape}, prediction.shape={prediction.shape}')\n",
    "    #print(y_true.head())\n",
    "    #print(prediction[0:6])\n",
    "\n",
    "    # https://stackoverflow.com/questions/152580/whats-the-canonical-way-to-check-for-type-in-python\n",
    "    pred = prediction\n",
    "    if not isinstance(pred, np.ndarray): pred = prediction.toarray()\n",
    "    print(type(y_true), type(prediction), type(pred))\n",
    "    try:\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "        print('macro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='macro'))) # default average=’macro’\n",
    "        print('micro roc_auc_score is %1.4f'%(roc_auc_score(y_true, pred, average='micro')))\n",
    "    except:\n",
    "        print(\"roc_auc_score error!!!\")\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, pred)\n",
    "        print(f'fpr={fpr}\\ntpr={tpr}\\nthresholds={thresholds}')\n",
    "    except:\n",
    "        print('roc_curve error!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Processing Pun jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      1413\n",
      "           1       0.43      0.27      0.33       261\n",
      "\n",
      "    accuracy                           0.83      1674\n",
      "   macro avg       0.65      0.60      0.62      1674\n",
      "weighted avg       0.81      0.83      0.81      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8309\t0.8309\t0.8309\tNone\n",
      "Macro\t0.6535\t0.6031\t0.6186\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.6031\n",
      "micro roc_auc_score is 0.6031\n",
      "fpr=[0.         0.06581741 1.        ]\n",
      "tpr=[0.         0.27203065 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Exaggeration jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1614\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.96      1674\n",
      "   macro avg       0.48      0.50      0.49      1674\n",
      "weighted avg       0.93      0.96      0.95      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9641\t0.9641\t0.9641\tNone\n",
      "Macro\t0.482\t0.5\t0.4908\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Anthropomorphism jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1634\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.98      1674\n",
      "   macro avg       0.49      0.50      0.49      1674\n",
      "weighted avg       0.95      0.98      0.96      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9761\t0.9761\t0.9761\tNone\n",
      "Macro\t0.488\t0.5\t0.4939\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Bridge_Inference jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90      1383\n",
      "           1       0.00      0.00      0.00       291\n",
      "\n",
      "    accuracy                           0.83      1674\n",
      "   macro avg       0.41      0.50      0.45      1674\n",
      "weighted avg       0.68      0.83      0.75      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.8261\t0.8261\t0.8261\tNone\n",
      "Macro\t0.413\t0.5\t0.4524\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Illogical jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1188\n",
      "           1       0.60      0.01      0.01       486\n",
      "\n",
      "    accuracy                           0.71      1674\n",
      "   macro avg       0.66      0.50      0.42      1674\n",
      "weighted avg       0.68      0.71      0.59      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.7102\t0.7102\t0.7102\tNone\n",
      "Macro\t0.6553\t0.5022\t0.4212\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5022\n",
      "micro roc_auc_score is 0.5022\n",
      "fpr=[0.        0.0016835 1.       ]\n",
      "tpr=[0.         0.00617284 1.        ]\n",
      "thresholds=[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Irony jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1639\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.98      1674\n",
      "   macro avg       0.49      0.50      0.49      1674\n",
      "weighted avg       0.96      0.98      0.97      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.979\t0.979\t0.979\tNone\n",
      "Macro\t0.4895\t0.5\t0.4947\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Imitation jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      1564\n",
      "           1       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.93      1674\n",
      "   macro avg       0.47      0.50      0.48      1674\n",
      "weighted avg       0.87      0.93      0.90      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.9342\t0.9342\t0.9342\tNone\n",
      "Macro\t0.4671\t0.5\t0.483\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Processing Others jokes...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.7145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83      1196\n",
      "           1       0.00      0.00      0.00       478\n",
      "\n",
      "    accuracy                           0.71      1674\n",
      "   macro avg       0.36      0.50      0.42      1674\n",
      "weighted avg       0.51      0.71      0.60      1674\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.7144\t0.7144\t0.7144\tNone\n",
      "Macro\t0.3572\t0.5\t0.4167\tNone\n",
      "y_true.shape=(1674,), prediction.shape=(1674,)\n",
      "<class 'pandas.core.series.Series'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5000\n",
      "micro roc_auc_score is 0.5000\n",
      "fpr=[0. 1.]\n",
      "tpr=[0. 1.]\n",
      "thresholds=[1 0]\n",
      "CPU times: user 110 ms, sys: 136 ms, total: 246 ms\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "#for category in categories:\n",
    "for category in categories:\n",
    "    printmd('**Processing {} jokes...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    \n",
    "    print_cls_report(test[category], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Multiple Binary Classifications - (Binary Relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use binary relevance, run \"pip install scikit-multilearn\" in advance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Next line refers to: http://scikit.ml/tutorial.html\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with GaussianNB()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.0980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.40      0.27       261\n",
      "           1       0.04      0.02      0.02        60\n",
      "           2       0.10      0.07      0.09        40\n",
      "           3       0.15      0.08      0.11       291\n",
      "           4       0.29      0.22      0.25       486\n",
      "           5       0.33      0.03      0.05        35\n",
      "           6       0.07      0.05      0.05       110\n",
      "           7       0.17      0.01      0.01       478\n",
      "\n",
      "   micro avg       0.21      0.14      0.17      1761\n",
      "   macro avg       0.17      0.11      0.11      1761\n",
      "weighted avg       0.20      0.14      0.14      1761\n",
      " samples avg       0.12      0.14      0.12      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2112\t0.1402\t0.1686\tNone\n",
      "Macro\t0.1702\t0.1088\t0.1073\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5118\n",
      "micro roc_auc_score is 0.5305\n",
      "roc_curve error!!!\n",
      "CPU times: user 1.05 s, sys: 225 ms, total: 1.27 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "#   with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with GaussianNB()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**BinaryRelevance with LinearSVC()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.20      0.23      0.21        40\n",
      "           3       0.25      0.18      0.21       291\n",
      "           4       0.32      0.33      0.32       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.09      0.05      0.06       110\n",
      "           7       0.23      0.01      0.01       478\n",
      "\n",
      "   micro avg       0.26      0.19      0.22      1761\n",
      "   macro avg       0.17      0.15      0.14      1761\n",
      "weighted avg       0.24      0.19      0.18      1761\n",
      " samples avg       0.17      0.19      0.18      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2643\t0.193\t0.2231\tNone\n",
      "Macro\t0.1671\t0.1516\t0.1414\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5314\n",
      "micro roc_auc_score is 0.5559\n",
      "roc_curve error!!!\n",
      "CPU times: user 815 ms, sys: 341 ms, total: 1.16 s\n",
      "Wall time: 653 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Next line refers to: http://scikit.ml/tutorial.html and \n",
    "#   http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "#classifier = BinaryRelevance(classifier=SVC(), require_dense=[False, True]) # 0.5 very bad!\n",
    "# https://scikit-learn.org/stable/modules/svm.html#unbalanced-problems\n",
    "classifier = BinaryRelevance(classifier=LinearSVC(class_weight='balanced')) # 0.5314\n",
    "#classifier = BinaryRelevance(classifier=LinearSVC()) # Test roc_auc_score is 0.5234\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**BinaryRelevance with LinearSVC()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classifier Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Classifier Chains with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.2264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.23      0.23      0.23        40\n",
      "           3       0.21      0.34      0.26       291\n",
      "           4       0.31      0.45      0.37       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.12      0.06      0.08       110\n",
      "           7       0.25      0.02      0.04       478\n",
      "\n",
      "   micro avg       0.26      0.26      0.26      1761\n",
      "   macro avg       0.17      0.19      0.16      1761\n",
      "weighted avg       0.24      0.26      0.21      1761\n",
      " samples avg       0.26      0.26      0.25      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2554\t0.2583\t0.2569\tNone\n",
      "Macro\t0.1702\t0.1911\t0.1606\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.csc.csc_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5327\n",
      "micro roc_auc_score is 0.5722\n",
      "roc_curve error!!!\n",
      "CPU times: user 1.45 s, sys: 1.58 s, total: 3.03 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "#classifier = ClassifierChain(LogisticRegression()) # Test roc_auc_score is 0.5159\n",
    "classifier = ClassifierChain(LinearSVC(class_weight='balanced')) #  0.5327\n",
    "\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Classifier Chains with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Label Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Label Powerset with LinearSVM()**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.1470\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.30       261\n",
      "           1       0.05      0.12      0.07        60\n",
      "           2       0.12      0.62      0.20        40\n",
      "           3       0.22      0.25      0.24       291\n",
      "           4       0.29      0.35      0.32       486\n",
      "           5       0.03      0.09      0.05        35\n",
      "           6       0.08      0.23      0.11       110\n",
      "           7       0.35      0.10      0.15       478\n",
      "\n",
      "   micro avg       0.20      0.27      0.23      1761\n",
      "   macro avg       0.17      0.28      0.18      1761\n",
      "weighted avg       0.25      0.27      0.23      1761\n",
      " samples avg       0.21      0.27      0.23      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.1989\t0.2674\t0.2281\tNone\n",
      "Macro\t0.1699\t0.2775\t0.1795\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5541\n",
      "micro roc_auc_score is 0.5522\n",
      "roc_curve error!!!\n",
      "CPU times: user 579 ms, sys: 914 ms, total: 1.49 s\n",
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize label powerset multi-label classifier\n",
    "#classifier = LabelPowerset(LogisticRegression()) # Test roc_auc_score is 0.5059\n",
    "classifier = LabelPowerset(LinearSVC(class_weight='balanced')) # 0.5541\n",
    "# Test roc_auc_score is 0.5312 if xtrain_tfidf_ngram, xtest_tfidf_ngram are used.\n",
    "# Test roc_auc_score is 0.5474 if xtrain_tfidf_ngram_chars, xtest_tfidf_ngram_chars are used\n",
    "\n",
    "# train\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(x_test)\n",
    "\n",
    "printmd('**Label Powerset with LinearSVM()**')\n",
    "print_cls_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with open('out/Skill_True.txt', 'w') as outF:\n",
    "#    outF.write(y_test.to_csv(sep='\\t', index=False))\n",
    "\n",
    "# https://stackoverflow.com/questions/36967666/transform-scipy-sparse-csr-to-pandas\n",
    "# with open('out/Skill_Pred.txt', 'w') as outF:\n",
    "#    outF.write(pd.DataFrame(predictions.toarray(), columns=list(y_test.columns)).to_csv(sep='\\t', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Adapted Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MLkNN**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.0998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.38      0.29       261\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.25      0.07      0.12        40\n",
      "           3       0.24      0.05      0.08       291\n",
      "           4       0.33      0.15      0.20       486\n",
      "           5       0.00      0.00      0.00        35\n",
      "           6       0.00      0.00      0.00       110\n",
      "           7       0.00      0.00      0.00       478\n",
      "\n",
      "   micro avg       0.26      0.11      0.15      1761\n",
      "   macro avg       0.13      0.08      0.09      1761\n",
      "weighted avg       0.17      0.11      0.11      1761\n",
      " samples avg       0.11      0.11      0.11      1761\n",
      "\n",
      "\tPrecision\tRecall\tF1\tSupport\n",
      "Micro\t0.2648\t0.1061\t0.1516\tNone\n",
      "Macro\t0.1324\t0.081\t0.086\tNone\n",
      "y_true.shape=(1674, 8), prediction.shape=(1674, 8)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'scipy.sparse.lil.lil_matrix'> <class 'numpy.ndarray'>\n",
      "macro roc_auc_score is 0.5164\n",
      "micro roc_auc_score is 0.5308\n",
      "roc_curve error!!!\n",
      "CPU times: user 8.2 s, sys: 3.28 s, total: 11.5 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_new = MLkNN(k=10)\n",
    "\n",
    "# Note that this classifier can throw up errors when handling sparse matrices.\n",
    "\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "# train\n",
    "classifier_new.fit(x_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions_new = classifier_new.predict(x_test)\n",
    "\n",
    "printmd('**MLkNN**')\n",
    "print_cls_report(y_test, predictions_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
